{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Vishwesh\\Anaconda3\\envs\\deep_l\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat, savemat\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from keras.optimizers import SGD, adam, nadam, Adagrad\n",
    "from keras.regularizers import l1,l2\n",
    "\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16569389845189943434\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5072204595\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 12247086378580759003\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all():\n",
    "    #input = loadmat('training_input_b6000.mat')\n",
    "    #output = loadmat('training_output_10th_order.mat')\n",
    "    \n",
    "    #input = loadmat('training_input_b6000_no_outliers.mat')\n",
    "    #output = loadmat('training_output_10th_order_no_outliers.mat')\n",
    "    \n",
    "    #input = loadmat('training_input_b9000_no_outliers.mat')\n",
    "    #output = loadmat('training_output_b9000_10th_order_no_outliers.mat')\n",
    "    \n",
    "    input = loadmat('training_input_b6000_final_no_outliers.mat')\n",
    "    output = loadmat('training_output_final_no_outliers.mat')\n",
    "    \n",
    "    #X = np.array(input['training_input_b9000_no_outliers'])\n",
    "    #X = np.array(input['training_input_b6000_no_outliers'])\n",
    "    #X = np.array(input['training_input_b6000'])\n",
    "    #X = np.array(input['input_matrix_randomized'])\n",
    "    X = np.array(input['training_input_b6000_final_no_outliers'])\n",
    "    \n",
    "    #y = np.array(output['output_matrix_randomized'])\n",
    "    #y = np.array(output['training_output_10th_order'])\n",
    "    #y = np.array(output['training_output_10th_order_no_outliers'])\n",
    "    #y = np.array(output['training_output_b9000_10th_order_no_outliers'])\n",
    "    y = np.array(output['training_output_final_no_outliers'])\n",
    "    \n",
    "    # Get dimensions of arrays\n",
    "    x_size = X.shape\n",
    "    print('Input Array Shape',x_size)\n",
    "    y_size = y.shape\n",
    "    print ('Output Array Shape',y_size)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defined Deep NN Function \n",
    "\n",
    "def build_nn2():\n",
    "    model = Sequential()\n",
    "    # Input layer with dimension 1 and hidden layer i with 128 neurons.\n",
    "    model.add(Dense(45, input_shape=(45,)))\n",
    "    model.add(Dense(400))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # Hidden layer j with 64 neurons plus activation layer.\n",
    "    model.add(Dense(66))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    # Hidden layer k with 64 neurons.\n",
    "    model.add(Dense(200))\n",
    "    # Output Layer.\n",
    "    model.add(Dense(66))\n",
    " \n",
    "    # Model is derived and compiled using mean square error as loss\n",
    "    # function, accuracy as metric and gradient descent optimizer.\n",
    "    model.compile(loss='mse', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #model = Sequential()\n",
    "    #model.add(Dropout(0.3, input_shape=(X.shape[1],)))\n",
    "    #model.add(Dense(180, activation='relu', W_regularizer=l1(),kernel_initializer='random_uniform'))\n",
    "    #model.add(Dense(160, activation='relu', W_regularizer=l1()))\n",
    "    #model.add(Dense(140, activation='relu', W_regularizer=l1()))\n",
    "    #model.add(Dense(120, activation='relu', W_regularizer=l1()))\n",
    "    #model.add(Dense(100, activation='relu', W_regularizer=l1()))\n",
    "    #model.add(Dense(80, activation='relu', W_regularizer=l1()))\n",
    "    #, init='normal' \"Removed from the below line\"\n",
    "    #model.add(Dense(66))\n",
    "    #opt = SGD(lr=1e-5, decay=1e-6)\n",
    "    #opt = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "    #mean_squared_error\n",
    "    #categorical_crossentropy\n",
    "    #model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "    #model.summary()\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Originally number of epochs was set to 1000, currently at 10.\n",
    "def train_nn(model, X, y, out_dir, val_size=0.2, n_epoch=1000):\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    csv_logger = CSVLogger(os.path.join(out_dir, 'results.csv'))\n",
    "\n",
    "    model.fit(X, y, epochs=n_epoch, batch_size=10000, verbose=1, shuffle=True, validation_split=val_size, callbacks=[csv_logger])\n",
    "    return model\n",
    "    \n",
    "    #, batch_size=5,verbose=0,callbacks=[csv_logger]\n",
    "    #regress = KerasRegressor(build_fn=model, epochs=n_epoch)\n",
    "    \n",
    "    #seed1 = 46\n",
    "    #kfold = KFold(n_splits=3, random_state=seed1)\n",
    "    #results = cross_val_score(regress, X, y, cv=kfold)\n",
    "    #print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "    \n",
    "    #regress.fit(X,y)\n",
    "    #return regress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_estimate(model, X, y, out_file, indices):\n",
    "    #y_pred = model.predict(X)\n",
    "\n",
    "    #y_pred = y_scaler.inverse_transform(y_pred)\n",
    "    #y = y_scaler.inverse_transform(y)\n",
    "\n",
    "    out_path = os.path.dirname(out_file)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "     \n",
    "    y_pred = model.predict(X)\n",
    "    savemat(out_file, mdict={'out_pred': y_pred, 'out_true': y, 'indices': indices})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_test_set_prediction(model, out_file):\n",
    "\n",
    "    #input_test = loadmat('testing_input_72_b6000.mat')\n",
    "    #input_test = loadmat('testing_input_72_b9000.mat')\n",
    "    #output_test = loadmat('testing_output_72_10th_order.mat')\n",
    "    \n",
    "    input_test = loadmat('test_sh_ln_dwmri.mat')\n",
    "    output_test = loadmat('test_set_output_10th_order_final.mat')\n",
    "    \n",
    "    #X_f_t = np.array(input_test['testing_input_72_b9000'])\n",
    "    X_f_t = np.array(input_test['test_sh_ln_dwmri.mat'])\n",
    "    y_f_t = np.array(output_test['test_set_output_10th_order_final'])\n",
    "    \n",
    "    # Get dimensions of arrays\n",
    "    x_size = X_f_t.shape\n",
    "    print('Hist 72: Input Array Shape',x_size)\n",
    "    y_size = y_f_t.shape\n",
    "    print ('Output Hist 72: Array Shape',y_size)\n",
    "    \n",
    "    # Make Predictions\n",
    "    pred = model.predict(X_f_t)\n",
    "    \n",
    "    # If output path does not exist, create it\n",
    "    out_path = os.path.dirname(out_file)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    \n",
    "    savemat(out_file, mdict={'out_pred': pred, 'out_true': y_f_t})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_vishabyte_predictions(model, out_file):\n",
    "    input_test = loadmat('b2000_invivo_vish_avg_vol.mat')\n",
    "    X_f_t = np.array(input_test['b2000_invivo_vish_avg_vol'])\n",
    "    # Get dimensions of arrays\n",
    "    x_size = X_f_t.shape\n",
    "    print('Vishabyte: Input Array Shape',x_size)\n",
    "    pred = model.predict(X_f_t)\n",
    "    \n",
    "    # If output path does not exist, create it\n",
    "    out_path = os.path.dirname(out_file)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "        \n",
    "    # In vivo save matrix\n",
    "    savemat(out_file, mdict={'out_pred': pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_wise_reprod_check_2(model, out_file_1, out_file_2):\n",
    "    # In vivo test\n",
    "    ts4_3ta = loadmat('sh_ts01_3tb_feed.mat')\n",
    "    ts4_3tb = loadmat('sh_ts01_austin_feed.mat')\n",
    "\n",
    "    # Make numpy arrays\n",
    "    X_3ta = np.array(ts4_3ta['sh_ts01_3tb_feed'])\n",
    "    X_3tb = np.array(ts4_3tb['sh_ts01_austin_feed'])\n",
    "\n",
    "    input_dummy_a = loadmat('in_vivo_dummy_a.mat')\n",
    "    input_dummy_b = loadmat('in_vivo_dummy_b.mat')\n",
    "\n",
    "    X_f_a = np.array(input_dummy_a['dummy_a'])\n",
    "    X_f_b = np.array(input_dummy_b['dummy_b'])\n",
    "    \n",
    "    # Pred 3TA TS04\n",
    "    pred = model.predict(X_3ta)\n",
    "    savemat(out_file_1, mdict={'predicted':pred})\n",
    "    #savemat('invivo_ts4_3ta.mat', mdict={'predicted':pred})\n",
    "    \n",
    "    # Pred 3TB TS04\n",
    "    predi = model.predict(X_3tb)\n",
    "    savemat(out_file_2, mdict={'predicted':predi})\n",
    "    #savemat('invivo_ts4_3tb.mat', mdict={'predicted':predi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_wise_reprod_check_3(model, out_file_1, out_file_2):\n",
    "    # In vivo test\n",
    "    ts4_3ta = loadmat('orig_hcp_feed.mat')\n",
    "    ts4_3tb = loadmat('retest_hcp_feed.mat')\n",
    "\n",
    "    # Make numpy arrays\n",
    "    X_3ta = np.array(ts4_3ta['orig_hcp_feed'])\n",
    "    X_3tb = np.array(ts4_3tb['retest_hcp_feed'])\n",
    "\n",
    "    #input_dummy_a = loadmat('in_vivo_dummy_a.mat')\n",
    "    #input_dummy_b = loadmat('in_vivo_dummy_b.mat')\n",
    "\n",
    "    #X_f_a = np.array(input_dummy_a['dummy_a'])\n",
    "    #X_f_b = np.array(input_dummy_b['dummy_b'])\n",
    "    \n",
    "    # Pred 3TA TS04\n",
    "    pred = model.predict(X_3ta)\n",
    "    savemat(out_file_1, mdict={'predicted':pred})\n",
    "    #savemat('invivo_ts4_3ta.mat', mdict={'predicted':pred})\n",
    "    \n",
    "    # Pred 3TB TS04\n",
    "    predi = model.predict(X_3tb)\n",
    "    savemat(out_file_2, mdict={'predicted':predi})\n",
    "    #savemat('invivo_ts4_3tb.mat', mdict={'predicted':predi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_wise_reprod_check(model, out_file_1, out_file_2):\n",
    "    # In vivo test\n",
    "    ts4_3ta = loadmat('sh_ts04_3ta_feed.mat')\n",
    "    ts4_3tb = loadmat('sh_ts04_3tb_feed.mat')\n",
    "\n",
    "    # Make numpy arrays\n",
    "    X_3ta = np.array(ts4_3ta['sh_ts04_3ta_feed'])\n",
    "    X_3tb = np.array(ts4_3tb['sh_ts04_3tb_feed'])\n",
    "\n",
    "    input_dummy_a = loadmat('in_vivo_dummy_a.mat')\n",
    "    input_dummy_b = loadmat('in_vivo_dummy_b.mat')\n",
    "\n",
    "    X_f_a = np.array(input_dummy_a['dummy_a'])\n",
    "    X_f_b = np.array(input_dummy_b['dummy_b'])\n",
    "    \n",
    "    # Pred 3TA TS04\n",
    "    pred = model.predict(X_3ta)\n",
    "    savemat(out_file_1, mdict={'predicted':pred})\n",
    "    #savemat('invivo_ts4_3ta.mat', mdict={'predicted':pred})\n",
    "    \n",
    "    # Pred 3TB TS04\n",
    "    predi = model.predict(X_3tb)\n",
    "    savemat(out_file_2, mdict={'predicted':predi})\n",
    "    #savemat('invivo_ts4_3tb.mat', mdict={'predicted':predi})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    t0 = time.time()\n",
    "\n",
    "    #args = parse_args()\n",
    "    work_dir = os.getcwd()\n",
    "    exp = 'Histo_b6000_HCP_test'\n",
    "    itr = 150 # Estimated from CV\n",
    "\n",
    "\n",
    "    print (\"Loading data\")\n",
    "    X, y = load_all()\n",
    "    indices = np.array(range(X.shape[0]))+1\n",
    "\n",
    "    out_start_dir = os.path.join(work_dir,exp)\n",
    "    #if not os.path.exists(out_start_dir):\n",
    "    #    os.makedirs(out_start_dir)\n",
    "\n",
    "    seed1 = 46\n",
    "    seed2 = 23\n",
    "\n",
    "    kf = KFold(n_splits=5, random_state=seed1,shuffle=True,)\n",
    "\n",
    "    fold_num = 0\n",
    "    model_D = build_nn2()\n",
    "    \n",
    "    for train, test in kf.split(X):\n",
    "        # Set up training / testing data\n",
    "        fold_num += 1\n",
    "        X_train = X[train,:]\n",
    "        y_train = y[train,:]\n",
    "        X_test = X[test,:]\n",
    "        y_test = y[test,:]\n",
    "        indices_train = indices[train]\n",
    "        indices_test = indices[test]\n",
    "        #X_train, X_test, y_train, y_test, X_scaler, y_scaler = norm_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "        # Want to submit this w/ 1000 different initializations\n",
    "        np.random.seed(seed=seed2)\n",
    "\n",
    "        # Deep NN\n",
    "        print (\"Training DNN with %d iterations, fold %d\" % (itr, fold_num))\n",
    "        out_dir_DNN = os.path.join(out_start_dir, str(fold_num))\n",
    "        model_D = train_nn(model_D, X_train, y_train, out_dir_DNN, n_epoch=itr, val_size=0.2)\n",
    "\n",
    "        print (\"Saving training outputs\")\n",
    "        end_dir = os.path.join(out_start_dir, str(fold_num), 'training.csv')\n",
    "        save_estimate(model_D, X_train, y_train, end_dir,indices_train)\n",
    "\n",
    "        print (\"Saving testing outputs\")\n",
    "        end_dir = os.path.join(out_start_dir, str(fold_num), 'testing.csv')\n",
    "        save_estimate(model_D, X_test, y_test, end_dir,indices_test)\n",
    "\n",
    "    #print (\"Saving Vishabyte outputs\")\n",
    "    #end_dir = os.path.join(out_start_dir, str('Vishabyte_Test'), 'result_vol_invivo_vish_b2000.mat')\n",
    "    #save_vishabyte_predictions(model_D, end_dir)\n",
    "\n",
    "    print (\"Saving Histology blind test outputs\")\n",
    "    end_dir = os.path.join(out_start_dir, str('Hist_Blind_72_Test'), 'result_b6000_testing_10th_order.mat')\n",
    "    save_test_set_prediction(model_D, end_dir)\n",
    "\n",
    "    #print (\"Saving Pair Wise Reprod Results\")\n",
    "    #end_dir_1 = os.path.join(out_start_dir, str('ISMRM_TS01_Test'), 'result_scan_a.mat')\n",
    "    #end_dir_2 = os.path.join(out_start_dir, str('ISMRM_TS01_Test'), 'result_scan_b.mat')\n",
    "    #pair_wise_reprod_check_2(model_D, end_dir_1, end_dir_2)\n",
    "    \n",
    "    print (\"Saving Pair Wise Reprod Results on HCP\")\n",
    "    end_dir_1 = os.path.join(out_start_dir, str('HCP_Test'), 'result_scan_a.mat')\n",
    "    end_dir_2 = os.path.join(out_start_dir, str('HCP_Test'), 'result_scan_b.mat')\n",
    "    pair_wise_reprod_check_3(model_D, end_dir_1, end_dir_2)\n",
    "    \n",
    "    print (\"Saving network for this fold\")\n",
    "    net_dir_DNN = (os.path.join(out_start_dir, 'nets'))\n",
    "    if not os.path.exists(net_dir_DNN):\n",
    "        os.makedirs(net_dir_DNN)\n",
    "    net_name = os.path.join(net_dir_DNN, exp+\"_model_fold\"+str(fold_num)+\".h5\")\n",
    "    model_D.save(net_name)\n",
    "\n",
    "    t1 = time.time()\n",
    "    total_time = t1-t0\n",
    "    print (total_time)\n",
    "\n",
    "    with open(os.path.join(work_dir,exp,'time.csv'),\"wb\") as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        writer.writerow([total_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Input Array Shape (44541, 45)\n",
      "Output Array Shape (44541, 66)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 45)                2070      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 400)               18400     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 66)                26466     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 66)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               13400     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 66)                13266     \n",
      "=================================================================\n",
      "Total params: 73,602\n",
      "Trainable params: 73,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training DNN with 150 iterations, fold 1\n",
      "Train on 28505 samples, validate on 7127 samples\n",
      "Epoch 1/150\n",
      "28505/28505 [==============================] - 1s 24us/step - loss: 0.0158 - acc: 0.4893 - val_loss: 0.0204 - val_acc: 0.9543\n",
      "Epoch 2/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0117 - acc: 0.7525 - val_loss: 0.0168 - val_acc: 0.9543\n",
      "Epoch 3/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0101 - acc: 0.7525 - val_loss: 0.0159 - val_acc: 0.9543\n",
      "Epoch 4/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0102 - acc: 0.7525 - val_loss: 0.0162 - val_acc: 0.9543\n",
      "Epoch 5/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0096 - acc: 0.7525 - val_loss: 0.0149 - val_acc: 0.9543\n",
      "Epoch 6/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0094 - acc: 0.7525 - val_loss: 0.0157 - val_acc: 0.9543\n",
      "Epoch 7/150\n",
      "28505/28505 [==============================] - 0s 14us/step - loss: 0.0094 - acc: 0.7525 - val_loss: 0.0152 - val_acc: 0.9543\n",
      "Epoch 8/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0095 - acc: 0.7525 - val_loss: 0.0143 - val_acc: 0.9543\n",
      "Epoch 9/150\n",
      "28505/28505 [==============================] - 0s 14us/step - loss: 0.0091 - acc: 0.7525 - val_loss: 0.0157 - val_acc: 0.9543\n",
      "Epoch 10/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0091 - acc: 0.7525 - val_loss: 0.0140 - val_acc: 0.9543\n",
      "Epoch 11/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0089 - acc: 0.7525 - val_loss: 0.0146 - val_acc: 0.9543\n",
      "Epoch 12/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0088 - acc: 0.7526 - val_loss: 0.0139 - val_acc: 0.9543\n",
      "Epoch 13/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0088 - acc: 0.7527 - val_loss: 0.0143 - val_acc: 0.9543\n",
      "Epoch 14/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0085 - acc: 0.7527 - val_loss: 0.0127 - val_acc: 0.9543\n",
      "Epoch 15/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0082 - acc: 0.7532 - val_loss: 0.0155 - val_acc: 0.9543\n",
      "Epoch 16/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0083 - acc: 0.7557 - val_loss: 0.0123 - val_acc: 0.9543\n",
      "Epoch 17/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0077 - acc: 0.7540 - val_loss: 0.0135 - val_acc: 0.9543\n",
      "Epoch 18/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0076 - acc: 0.7579 - val_loss: 0.0116 - val_acc: 0.9543\n",
      "Epoch 19/150\n",
      "28505/28505 [==============================] - 0s 17us/step - loss: 0.0076 - acc: 0.7573 - val_loss: 0.0130 - val_acc: 0.9543\n",
      "Epoch 20/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0075 - acc: 0.7616 - val_loss: 0.0119 - val_acc: 0.9543\n",
      "Epoch 21/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0074 - acc: 0.7628 - val_loss: 0.0124 - val_acc: 0.9545\n",
      "Epoch 22/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0072 - acc: 0.7698 - val_loss: 0.0108 - val_acc: 0.9543\n",
      "Epoch 23/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0072 - acc: 0.7641 - val_loss: 0.0141 - val_acc: 0.9496\n",
      "Epoch 24/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0073 - acc: 0.7712 - val_loss: 0.0108 - val_acc: 0.9543\n",
      "Epoch 25/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0066 - acc: 0.7702 - val_loss: 0.0108 - val_acc: 0.9545\n",
      "Epoch 26/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0065 - acc: 0.7739 - val_loss: 0.0118 - val_acc: 0.9547\n",
      "Epoch 27/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0067 - acc: 0.7768 - val_loss: 0.0098 - val_acc: 0.9543\n",
      "Epoch 28/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0067 - acc: 0.7718 - val_loss: 0.0118 - val_acc: 0.9547\n",
      "Epoch 29/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0066 - acc: 0.7780 - val_loss: 0.0100 - val_acc: 0.9544\n",
      "Epoch 30/150\n",
      "28505/28505 [==============================] - 0s 17us/step - loss: 0.0064 - acc: 0.7774 - val_loss: 0.0117 - val_acc: 0.9552\n",
      "Epoch 31/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0066 - acc: 0.7790 - val_loss: 0.0099 - val_acc: 0.9543\n",
      "Epoch 32/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0064 - acc: 0.7741 - val_loss: 0.0117 - val_acc: 0.9523\n",
      "Epoch 33/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0063 - acc: 0.7788 - val_loss: 0.0095 - val_acc: 0.9543\n",
      "Epoch 34/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0059 - acc: 0.7775 - val_loss: 0.0107 - val_acc: 0.9547\n",
      "Epoch 35/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0060 - acc: 0.7791 - val_loss: 0.0103 - val_acc: 0.9548\n",
      "Epoch 36/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0063 - acc: 0.7780 - val_loss: 0.0093 - val_acc: 0.9544\n",
      "Epoch 37/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0062 - acc: 0.7717 - val_loss: 0.0106 - val_acc: 0.9548\n",
      "Epoch 38/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0059 - acc: 0.7808 - val_loss: 0.0092 - val_acc: 0.9544\n",
      "Epoch 39/150\n",
      "28505/28505 [==============================] - 0s 14us/step - loss: 0.0061 - acc: 0.7742 - val_loss: 0.0112 - val_acc: 0.9485\n",
      "Epoch 40/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0059 - acc: 0.7774 - val_loss: 0.0092 - val_acc: 0.9544\n",
      "Epoch 41/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0056 - acc: 0.7743 - val_loss: 0.0103 - val_acc: 0.9547\n",
      "Epoch 42/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0059 - acc: 0.7748 - val_loss: 0.0097 - val_acc: 0.9536\n",
      "Epoch 43/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0057 - acc: 0.7768 - val_loss: 0.0090 - val_acc: 0.9544\n",
      "Epoch 44/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0059 - acc: 0.7754 - val_loss: 0.0113 - val_acc: 0.9493\n",
      "Epoch 45/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0059 - acc: 0.7758 - val_loss: 0.0092 - val_acc: 0.9544\n",
      "Epoch 46/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0056 - acc: 0.7720 - val_loss: 0.0098 - val_acc: 0.9538\n",
      "Epoch 47/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0057 - acc: 0.7720 - val_loss: 0.0097 - val_acc: 0.9544\n",
      "Epoch 48/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0056 - acc: 0.7768 - val_loss: 0.0095 - val_acc: 0.9545\n",
      "Epoch 49/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0057 - acc: 0.7726 - val_loss: 0.0086 - val_acc: 0.9544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0058 - acc: 0.7700 - val_loss: 0.0105 - val_acc: 0.9481\n",
      "Epoch 51/150\n",
      "28505/28505 [==============================] - 0s 17us/step - loss: 0.0054 - acc: 0.7727 - val_loss: 0.0086 - val_acc: 0.9544\n",
      "Epoch 52/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0053 - acc: 0.7722 - val_loss: 0.0100 - val_acc: 0.9517\n",
      "Epoch 53/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0055 - acc: 0.7742 - val_loss: 0.0087 - val_acc: 0.9536\n",
      "Epoch 54/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0056 - acc: 0.7741 - val_loss: 0.0097 - val_acc: 0.9552\n",
      "Epoch 55/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0053 - acc: 0.7741 - val_loss: 0.0085 - val_acc: 0.9545\n",
      "Epoch 56/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0055 - acc: 0.7686 - val_loss: 0.0104 - val_acc: 0.9478\n",
      "Epoch 57/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0053 - acc: 0.7685 - val_loss: 0.0083 - val_acc: 0.9545\n",
      "Epoch 58/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0055 - acc: 0.7687 - val_loss: 0.0102 - val_acc: 0.9548\n",
      "Epoch 59/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0053 - acc: 0.7706 - val_loss: 0.0086 - val_acc: 0.9538\n",
      "Epoch 60/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0052 - acc: 0.7725 - val_loss: 0.0098 - val_acc: 0.9545\n",
      "Epoch 61/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0053 - acc: 0.7719 - val_loss: 0.0094 - val_acc: 0.9545\n",
      "Epoch 62/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0055 - acc: 0.7713 - val_loss: 0.0081 - val_acc: 0.9547\n",
      "Epoch 63/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0053 - acc: 0.7702 - val_loss: 0.0095 - val_acc: 0.9534\n",
      "Epoch 64/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0052 - acc: 0.7708 - val_loss: 0.0090 - val_acc: 0.9551\n",
      "Epoch 65/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0051 - acc: 0.7737 - val_loss: 0.0083 - val_acc: 0.9543\n",
      "Epoch 66/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0053 - acc: 0.7680 - val_loss: 0.0105 - val_acc: 0.9477\n",
      "Epoch 67/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0053 - acc: 0.7686 - val_loss: 0.0083 - val_acc: 0.9541\n",
      "Epoch 68/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0050 - acc: 0.7708 - val_loss: 0.0088 - val_acc: 0.9548\n",
      "Epoch 69/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0050 - acc: 0.7713 - val_loss: 0.0092 - val_acc: 0.9519\n",
      "Epoch 70/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0052 - acc: 0.7744 - val_loss: 0.0082 - val_acc: 0.9547\n",
      "Epoch 71/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0051 - acc: 0.7693 - val_loss: 0.0102 - val_acc: 0.9562\n",
      "Epoch 72/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0053 - acc: 0.7707 - val_loss: 0.0080 - val_acc: 0.9551\n",
      "Epoch 73/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0051 - acc: 0.7709 - val_loss: 0.0095 - val_acc: 0.9550\n",
      "Epoch 74/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0050 - acc: 0.7703 - val_loss: 0.0081 - val_acc: 0.9543\n",
      "Epoch 75/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0051 - acc: 0.7704 - val_loss: 0.0093 - val_acc: 0.9555\n",
      "Epoch 76/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0050 - acc: 0.7742 - val_loss: 0.0084 - val_acc: 0.9543\n",
      "Epoch 77/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0050 - acc: 0.7700 - val_loss: 0.0086 - val_acc: 0.9551\n",
      "Epoch 78/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0049 - acc: 0.7727 - val_loss: 0.0088 - val_acc: 0.9550\n",
      "Epoch 79/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0050 - acc: 0.7748 - val_loss: 0.0078 - val_acc: 0.9544\n",
      "Epoch 80/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0053 - acc: 0.7661 - val_loss: 0.0104 - val_acc: 0.9561\n",
      "Epoch 81/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0051 - acc: 0.7711 - val_loss: 0.0080 - val_acc: 0.9543\n",
      "Epoch 82/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0048 - acc: 0.7724 - val_loss: 0.0089 - val_acc: 0.9562\n",
      "Epoch 83/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0048 - acc: 0.7751 - val_loss: 0.0080 - val_acc: 0.9545\n",
      "Epoch 84/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0048 - acc: 0.7696 - val_loss: 0.0089 - val_acc: 0.9551\n",
      "Epoch 85/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0049 - acc: 0.7739 - val_loss: 0.0078 - val_acc: 0.9543\n",
      "Epoch 86/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0051 - acc: 0.7683 - val_loss: 0.0104 - val_acc: 0.9565\n",
      "Epoch 87/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0051 - acc: 0.7715 - val_loss: 0.0078 - val_acc: 0.9544\n",
      "Epoch 88/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0048 - acc: 0.7762 - val_loss: 0.0089 - val_acc: 0.9580\n",
      "Epoch 89/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0048 - acc: 0.7737 - val_loss: 0.0083 - val_acc: 0.9547\n",
      "Epoch 90/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0048 - acc: 0.7725 - val_loss: 0.0084 - val_acc: 0.9566\n",
      "Epoch 91/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0050 - acc: 0.7726 - val_loss: 0.0084 - val_acc: 0.9566\n",
      "Epoch 92/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0047 - acc: 0.7767 - val_loss: 0.0078 - val_acc: 0.9548\n",
      "Epoch 93/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0049 - acc: 0.7708 - val_loss: 0.0106 - val_acc: 0.9482\n",
      "Epoch 94/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0052 - acc: 0.7705 - val_loss: 0.0076 - val_acc: 0.9547\n",
      "Epoch 95/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0047 - acc: 0.7720 - val_loss: 0.0088 - val_acc: 0.9582\n",
      "Epoch 96/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0047 - acc: 0.7742 - val_loss: 0.0080 - val_acc: 0.9554\n",
      "Epoch 97/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0047 - acc: 0.7725 - val_loss: 0.0085 - val_acc: 0.9554\n",
      "Epoch 98/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0047 - acc: 0.7742 - val_loss: 0.0081 - val_acc: 0.9592\n",
      "Epoch 99/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0048 - acc: 0.7790 - val_loss: 0.0088 - val_acc: 0.9554\n",
      "Epoch 100/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0049 - acc: 0.7747 - val_loss: 0.0073 - val_acc: 0.9544\n",
      "Epoch 101/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0051 - acc: 0.7732 - val_loss: 0.0096 - val_acc: 0.9534\n",
      "Epoch 102/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0048 - acc: 0.7718 - val_loss: 0.0078 - val_acc: 0.9555\n",
      "Epoch 103/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7745 - val_loss: 0.0084 - val_acc: 0.9575\n",
      "Epoch 104/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0046 - acc: 0.7772 - val_loss: 0.0082 - val_acc: 0.9576\n",
      "Epoch 105/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0047 - acc: 0.7812 - val_loss: 0.0083 - val_acc: 0.9583\n",
      "Epoch 106/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0046 - acc: 0.7754 - val_loss: 0.0078 - val_acc: 0.9587\n",
      "Epoch 107/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0046 - acc: 0.7822 - val_loss: 0.0099 - val_acc: 0.9569\n",
      "Epoch 108/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0052 - acc: 0.7707 - val_loss: 0.0073 - val_acc: 0.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0047 - acc: 0.7713 - val_loss: 0.0084 - val_acc: 0.9603\n",
      "Epoch 110/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7818 - val_loss: 0.0078 - val_acc: 0.9559\n",
      "Epoch 111/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7782 - val_loss: 0.0086 - val_acc: 0.9596\n",
      "Epoch 112/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0047 - acc: 0.7810 - val_loss: 0.0079 - val_acc: 0.9603\n",
      "Epoch 113/150\n",
      "28505/28505 [==============================] - 0s 11us/step - loss: 0.0046 - acc: 0.7798 - val_loss: 0.0082 - val_acc: 0.9573\n",
      "Epoch 114/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0045 - acc: 0.7818 - val_loss: 0.0079 - val_acc: 0.9597\n",
      "Epoch 115/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7794 - val_loss: 0.0089 - val_acc: 0.9551\n",
      "Epoch 116/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0049 - acc: 0.7758 - val_loss: 0.0070 - val_acc: 0.9541\n",
      "Epoch 117/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0048 - acc: 0.7697 - val_loss: 0.0085 - val_acc: 0.9579\n",
      "Epoch 118/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0045 - acc: 0.7833 - val_loss: 0.0076 - val_acc: 0.9595\n",
      "Epoch 119/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7845 - val_loss: 0.0082 - val_acc: 0.9572\n",
      "Epoch 120/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7833 - val_loss: 0.0074 - val_acc: 0.9590\n",
      "Epoch 121/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7793 - val_loss: 0.0094 - val_acc: 0.9568\n",
      "Epoch 122/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0048 - acc: 0.7823 - val_loss: 0.0072 - val_acc: 0.9544\n",
      "Epoch 123/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7750 - val_loss: 0.0086 - val_acc: 0.9595\n",
      "Epoch 124/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7836 - val_loss: 0.0076 - val_acc: 0.9573\n",
      "Epoch 125/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7780 - val_loss: 0.0082 - val_acc: 0.9586\n",
      "Epoch 126/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7867 - val_loss: 0.0075 - val_acc: 0.9592\n",
      "Epoch 127/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7754 - val_loss: 0.0091 - val_acc: 0.9513\n",
      "Epoch 128/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0048 - acc: 0.7786 - val_loss: 0.0071 - val_acc: 0.9541\n",
      "Epoch 129/150\n",
      "28505/28505 [==============================] - 0s 15us/step - loss: 0.0046 - acc: 0.7766 - val_loss: 0.0087 - val_acc: 0.9592\n",
      "Epoch 130/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7845 - val_loss: 0.0075 - val_acc: 0.9596\n",
      "Epoch 131/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0044 - acc: 0.7884 - val_loss: 0.0082 - val_acc: 0.9575\n",
      "Epoch 132/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7841 - val_loss: 0.0076 - val_acc: 0.9572\n",
      "Epoch 133/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7791 - val_loss: 0.0088 - val_acc: 0.9552\n",
      "Epoch 134/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0047 - acc: 0.7844 - val_loss: 0.0070 - val_acc: 0.9558\n",
      "Epoch 135/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7797 - val_loss: 0.0085 - val_acc: 0.9597\n",
      "Epoch 136/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0044 - acc: 0.7884 - val_loss: 0.0075 - val_acc: 0.9571\n",
      "Epoch 137/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0044 - acc: 0.7814 - val_loss: 0.0078 - val_acc: 0.9603\n",
      "Epoch 138/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0045 - acc: 0.7885 - val_loss: 0.0085 - val_acc: 0.9561\n",
      "Epoch 139/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0045 - acc: 0.7846 - val_loss: 0.0070 - val_acc: 0.9566\n",
      "Epoch 140/150\n",
      "28505/28505 [==============================] - 0s 16us/step - loss: 0.0045 - acc: 0.7752 - val_loss: 0.0093 - val_acc: 0.9416\n",
      "Epoch 141/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0046 - acc: 0.7817 - val_loss: 0.0073 - val_acc: 0.9571\n",
      "Epoch 142/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7878 - val_loss: 0.0081 - val_acc: 0.9592\n",
      "Epoch 143/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0044 - acc: 0.7853 - val_loss: 0.0077 - val_acc: 0.9595\n",
      "Epoch 144/150\n",
      "28505/28505 [==============================] - 0s 13us/step - loss: 0.0044 - acc: 0.7912 - val_loss: 0.0075 - val_acc: 0.9592\n",
      "Epoch 145/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7809 - val_loss: 0.0087 - val_acc: 0.9517\n",
      "Epoch 146/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7820 - val_loss: 0.0069 - val_acc: 0.9561\n",
      "Epoch 147/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7759 - val_loss: 0.0086 - val_acc: 0.9576\n",
      "Epoch 148/150\n",
      "28505/28505 [==============================] - 0s 12us/step - loss: 0.0044 - acc: 0.7898 - val_loss: 0.0073 - val_acc: 0.9585\n",
      "Epoch 149/150\n",
      "28505/28505 [==============================] - 0s 14us/step - loss: 0.0043 - acc: 0.7875 - val_loss: 0.0082 - val_acc: 0.9583\n",
      "Epoch 150/150\n",
      "28505/28505 [==============================] - 0s 17us/step - loss: 0.0045 - acc: 0.7874 - val_loss: 0.0073 - val_acc: 0.9586\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Training DNN with 150 iterations, fold 2\n",
      "Train on 28506 samples, validate on 7127 samples\n",
      "Epoch 1/150\n",
      "28506/28506 [==============================] - 0s 11us/step - loss: 0.0044 - acc: 0.7906 - val_loss: 0.0086 - val_acc: 0.9557\n",
      "Epoch 2/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7845 - val_loss: 0.0070 - val_acc: 0.9543\n",
      "Epoch 3/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0044 - acc: 0.7766 - val_loss: 0.0084 - val_acc: 0.9580\n",
      "Epoch 4/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0044 - acc: 0.7906 - val_loss: 0.0072 - val_acc: 0.9555\n",
      "Epoch 5/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0045 - acc: 0.7852 - val_loss: 0.0083 - val_acc: 0.9600\n",
      "Epoch 6/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0044 - acc: 0.7911 - val_loss: 0.0076 - val_acc: 0.9569\n",
      "Epoch 7/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0044 - acc: 0.7898 - val_loss: 0.0078 - val_acc: 0.9583\n",
      "Epoch 8/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0043 - acc: 0.7945 - val_loss: 0.0078 - val_acc: 0.9586\n",
      "Epoch 9/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0043 - acc: 0.7892 - val_loss: 0.0077 - val_acc: 0.9595\n",
      "Epoch 10/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7935 - val_loss: 0.0075 - val_acc: 0.9552\n",
      "Epoch 11/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0044 - acc: 0.7825 - val_loss: 0.0099 - val_acc: 0.9203\n",
      "Epoch 12/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0049 - acc: 0.7709 - val_loss: 0.0071 - val_acc: 0.9576\n",
      "Epoch 13/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0042 - acc: 0.7859 - val_loss: 0.0078 - val_acc: 0.9595\n",
      "Epoch 14/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7959 - val_loss: 0.0074 - val_acc: 0.9575\n",
      "Epoch 15/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7878 - val_loss: 0.0078 - val_acc: 0.9614\n",
      "Epoch 16/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7931 - val_loss: 0.0077 - val_acc: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0043 - acc: 0.7909 - val_loss: 0.0073 - val_acc: 0.9573\n",
      "Epoch 18/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0044 - acc: 0.7832 - val_loss: 0.0095 - val_acc: 0.9360\n",
      "Epoch 19/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0047 - acc: 0.7800 - val_loss: 0.0071 - val_acc: 0.9559\n",
      "Epoch 20/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7886 - val_loss: 0.0079 - val_acc: 0.9586\n",
      "Epoch 21/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0042 - acc: 0.7952 - val_loss: 0.0073 - val_acc: 0.9595\n",
      "Epoch 22/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0043 - acc: 0.7895 - val_loss: 0.0079 - val_acc: 0.9554\n",
      "Epoch 23/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0042 - acc: 0.7991 - val_loss: 0.0072 - val_acc: 0.9566\n",
      "Epoch 24/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7828 - val_loss: 0.0090 - val_acc: 0.9298\n",
      "Epoch 25/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0046 - acc: 0.7767 - val_loss: 0.0069 - val_acc: 0.9545\n",
      "Epoch 26/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0043 - acc: 0.7837 - val_loss: 0.0081 - val_acc: 0.9562\n",
      "Epoch 27/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0043 - acc: 0.7918 - val_loss: 0.0072 - val_acc: 0.9569\n",
      "Epoch 28/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7859 - val_loss: 0.0078 - val_acc: 0.9566\n",
      "Epoch 29/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0042 - acc: 0.7957 - val_loss: 0.0076 - val_acc: 0.9572\n",
      "Epoch 30/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0043 - acc: 0.7911 - val_loss: 0.0073 - val_acc: 0.9580\n",
      "Epoch 31/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7876 - val_loss: 0.0091 - val_acc: 0.9352\n",
      "Epoch 32/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0045 - acc: 0.7800 - val_loss: 0.0069 - val_acc: 0.9558\n",
      "Epoch 33/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7833 - val_loss: 0.0080 - val_acc: 0.9589\n",
      "Epoch 34/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0042 - acc: 0.7944 - val_loss: 0.0072 - val_acc: 0.9568\n",
      "Epoch 35/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0042 - acc: 0.7904 - val_loss: 0.0080 - val_acc: 0.9576\n",
      "Epoch 36/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0043 - acc: 0.7910 - val_loss: 0.0071 - val_acc: 0.9552\n",
      "Epoch 37/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0043 - acc: 0.7803 - val_loss: 0.0082 - val_acc: 0.9536\n",
      "Epoch 38/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0043 - acc: 0.7901 - val_loss: 0.0069 - val_acc: 0.9562\n",
      "Epoch 39/150\n",
      "28506/28506 [==============================] - 1s 20us/step - loss: 0.0044 - acc: 0.7823 - val_loss: 0.0083 - val_acc: 0.9540\n",
      "Epoch 40/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0042 - acc: 0.7933 - val_loss: 0.0071 - val_acc: 0.9559\n",
      "Epoch 41/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7783 - val_loss: 0.0080 - val_acc: 0.9499\n",
      "Epoch 42/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7924 - val_loss: 0.0071 - val_acc: 0.9544\n",
      "Epoch 43/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7834 - val_loss: 0.0082 - val_acc: 0.9461\n",
      "Epoch 44/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0043 - acc: 0.7875 - val_loss: 0.0069 - val_acc: 0.9568\n",
      "Epoch 45/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0043 - acc: 0.7876 - val_loss: 0.0086 - val_acc: 0.9526\n",
      "Epoch 46/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7912 - val_loss: 0.0070 - val_acc: 0.9565\n",
      "Epoch 47/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7873 - val_loss: 0.0080 - val_acc: 0.9510\n",
      "Epoch 48/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0042 - acc: 0.7930 - val_loss: 0.0073 - val_acc: 0.9547\n",
      "Epoch 49/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0042 - acc: 0.7930 - val_loss: 0.0075 - val_acc: 0.9569\n",
      "Epoch 50/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7908 - val_loss: 0.0082 - val_acc: 0.9447\n",
      "Epoch 51/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7836 - val_loss: 0.0067 - val_acc: 0.9543\n",
      "Epoch 52/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7812 - val_loss: 0.0080 - val_acc: 0.9543\n",
      "Epoch 53/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0041 - acc: 0.7946 - val_loss: 0.0071 - val_acc: 0.9572\n",
      "Epoch 54/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0041 - acc: 0.7927 - val_loss: 0.0077 - val_acc: 0.9545\n",
      "Epoch 55/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7958 - val_loss: 0.0074 - val_acc: 0.9562\n",
      "Epoch 56/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7926 - val_loss: 0.0071 - val_acc: 0.9580\n",
      "Epoch 57/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7930 - val_loss: 0.0091 - val_acc: 0.9272\n",
      "Epoch 58/150\n",
      "28506/28506 [==============================] - 1s 20us/step - loss: 0.0044 - acc: 0.7822 - val_loss: 0.0069 - val_acc: 0.9538\n",
      "Epoch 59/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0041 - acc: 0.7822 - val_loss: 0.0078 - val_acc: 0.9533\n",
      "Epoch 60/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.7954 - val_loss: 0.0072 - val_acc: 0.9557\n",
      "Epoch 61/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.7898 - val_loss: 0.0078 - val_acc: 0.9558\n",
      "Epoch 62/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.7952 - val_loss: 0.0069 - val_acc: 0.9572\n",
      "Epoch 63/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7870 - val_loss: 0.0087 - val_acc: 0.9224\n",
      "Epoch 64/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0043 - acc: 0.7799 - val_loss: 0.0069 - val_acc: 0.9544\n",
      "Epoch 65/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.7881 - val_loss: 0.0079 - val_acc: 0.9530\n",
      "Epoch 66/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0041 - acc: 0.7944 - val_loss: 0.0071 - val_acc: 0.9564\n",
      "Epoch 67/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.7912 - val_loss: 0.0080 - val_acc: 0.9530\n",
      "Epoch 68/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0042 - acc: 0.7958 - val_loss: 0.0071 - val_acc: 0.9573\n",
      "Epoch 69/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0041 - acc: 0.7918 - val_loss: 0.0085 - val_acc: 0.9228\n",
      "Epoch 70/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0043 - acc: 0.7816 - val_loss: 0.0067 - val_acc: 0.9545\n",
      "Epoch 71/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7839 - val_loss: 0.0080 - val_acc: 0.9484\n",
      "Epoch 72/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7960 - val_loss: 0.0072 - val_acc: 0.9569\n",
      "Epoch 73/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.7874 - val_loss: 0.0077 - val_acc: 0.9453\n",
      "Epoch 74/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7973 - val_loss: 0.0073 - val_acc: 0.9547\n",
      "Epoch 75/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7898 - val_loss: 0.0074 - val_acc: 0.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.8015 - val_loss: 0.0071 - val_acc: 0.9564\n",
      "Epoch 77/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0042 - acc: 0.7853 - val_loss: 0.0093 - val_acc: 0.8976\n",
      "Epoch 78/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0044 - acc: 0.7730 - val_loss: 0.0068 - val_acc: 0.9548\n",
      "Epoch 79/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7886 - val_loss: 0.0078 - val_acc: 0.9496\n",
      "Epoch 80/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7946 - val_loss: 0.0071 - val_acc: 0.9548\n",
      "Epoch 81/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7945 - val_loss: 0.0075 - val_acc: 0.9544\n",
      "Epoch 82/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.7956 - val_loss: 0.0074 - val_acc: 0.9538\n",
      "Epoch 83/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0040 - acc: 0.7944 - val_loss: 0.0075 - val_acc: 0.9561\n",
      "Epoch 84/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0041 - acc: 0.7980 - val_loss: 0.0067 - val_acc: 0.9554\n",
      "Epoch 85/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0043 - acc: 0.7749 - val_loss: 0.0086 - val_acc: 0.9293\n",
      "Epoch 86/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7899 - val_loss: 0.0070 - val_acc: 0.9555\n",
      "Epoch 87/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7878 - val_loss: 0.0076 - val_acc: 0.9442\n",
      "Epoch 88/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0040 - acc: 0.7958 - val_loss: 0.0071 - val_acc: 0.9559\n",
      "Epoch 89/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0040 - acc: 0.7936 - val_loss: 0.0079 - val_acc: 0.9436\n",
      "Epoch 90/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7951 - val_loss: 0.0067 - val_acc: 0.9559\n",
      "Epoch 91/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0041 - acc: 0.7865 - val_loss: 0.0084 - val_acc: 0.9282\n",
      "Epoch 92/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0041 - acc: 0.7869 - val_loss: 0.0069 - val_acc: 0.9548\n",
      "Epoch 93/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7849 - val_loss: 0.0077 - val_acc: 0.9474\n",
      "Epoch 94/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0040 - acc: 0.7976 - val_loss: 0.0071 - val_acc: 0.9547\n",
      "Epoch 95/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7934 - val_loss: 0.0079 - val_acc: 0.9421\n",
      "Epoch 96/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0041 - acc: 0.7934 - val_loss: 0.0069 - val_acc: 0.9569\n",
      "Epoch 97/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0042 - acc: 0.7836 - val_loss: 0.0085 - val_acc: 0.9381\n",
      "Epoch 98/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0041 - acc: 0.7937 - val_loss: 0.0068 - val_acc: 0.9550\n",
      "Epoch 99/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0040 - acc: 0.7862 - val_loss: 0.0078 - val_acc: 0.9356\n",
      "Epoch 100/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7944 - val_loss: 0.0070 - val_acc: 0.9557\n",
      "Epoch 101/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7884 - val_loss: 0.0078 - val_acc: 0.9470\n",
      "Epoch 102/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7956 - val_loss: 0.0069 - val_acc: 0.9554\n",
      "Epoch 103/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0041 - acc: 0.7876 - val_loss: 0.0087 - val_acc: 0.9151\n",
      "Epoch 104/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0041 - acc: 0.7895 - val_loss: 0.0068 - val_acc: 0.9540\n",
      "Epoch 105/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0040 - acc: 0.7855 - val_loss: 0.0079 - val_acc: 0.9352\n",
      "Epoch 106/150\n",
      "28506/28506 [==============================] - 1s 20us/step - loss: 0.0040 - acc: 0.7954 - val_loss: 0.0069 - val_acc: 0.9547\n",
      "Epoch 107/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0040 - acc: 0.7847 - val_loss: 0.0078 - val_acc: 0.9433\n",
      "Epoch 108/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0040 - acc: 0.7963 - val_loss: 0.0069 - val_acc: 0.9565\n",
      "Epoch 109/150\n",
      "28506/28506 [==============================] - 1s 20us/step - loss: 0.0040 - acc: 0.7880 - val_loss: 0.0083 - val_acc: 0.9245\n",
      "Epoch 110/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0041 - acc: 0.7873 - val_loss: 0.0068 - val_acc: 0.9545\n",
      "Epoch 111/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7854 - val_loss: 0.0077 - val_acc: 0.9416\n",
      "Epoch 112/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0040 - acc: 0.7947 - val_loss: 0.0070 - val_acc: 0.9538\n",
      "Epoch 113/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0040 - acc: 0.7916 - val_loss: 0.0080 - val_acc: 0.9429\n",
      "Epoch 114/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0040 - acc: 0.7939 - val_loss: 0.0067 - val_acc: 0.9545\n",
      "Epoch 115/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0040 - acc: 0.7920 - val_loss: 0.0081 - val_acc: 0.9277\n",
      "Epoch 116/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0040 - acc: 0.7920 - val_loss: 0.0067 - val_acc: 0.9540\n",
      "Epoch 117/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0040 - acc: 0.7789 - val_loss: 0.0077 - val_acc: 0.9404\n",
      "Epoch 118/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0039 - acc: 0.7980 - val_loss: 0.0071 - val_acc: 0.9515\n",
      "Epoch 119/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0040 - acc: 0.7938 - val_loss: 0.0076 - val_acc: 0.9537\n",
      "Epoch 120/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7925 - val_loss: 0.0070 - val_acc: 0.9502\n",
      "Epoch 121/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0040 - acc: 0.7971 - val_loss: 0.0080 - val_acc: 0.9273\n",
      "Epoch 122/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7858 - val_loss: 0.0066 - val_acc: 0.9540\n",
      "Epoch 123/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0041 - acc: 0.7779 - val_loss: 0.0079 - val_acc: 0.9327\n",
      "Epoch 124/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0039 - acc: 0.7961 - val_loss: 0.0068 - val_acc: 0.9550\n",
      "Epoch 125/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0039 - acc: 0.7908 - val_loss: 0.0077 - val_acc: 0.9384\n",
      "Epoch 126/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7947 - val_loss: 0.0068 - val_acc: 0.9543\n",
      "Epoch 127/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7943 - val_loss: 0.0081 - val_acc: 0.9408\n",
      "Epoch 128/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7923 - val_loss: 0.0066 - val_acc: 0.9536\n",
      "Epoch 129/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7802 - val_loss: 0.0080 - val_acc: 0.9268\n",
      "Epoch 130/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0040 - acc: 0.7978 - val_loss: 0.0070 - val_acc: 0.9540\n",
      "Epoch 131/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0039 - acc: 0.7892 - val_loss: 0.0075 - val_acc: 0.9442\n",
      "Epoch 132/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0039 - acc: 0.8001 - val_loss: 0.0070 - val_acc: 0.9522\n",
      "Epoch 133/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0039 - acc: 0.7962 - val_loss: 0.0079 - val_acc: 0.9415\n",
      "Epoch 134/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7937 - val_loss: 0.0066 - val_acc: 0.9543\n",
      "Epoch 135/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0041 - acc: 0.7750 - val_loss: 0.0081 - val_acc: 0.9234\n",
      "Epoch 136/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0039 - acc: 0.7976 - val_loss: 0.0069 - val_acc: 0.9547\n",
      "Epoch 137/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0039 - acc: 0.7920 - val_loss: 0.0078 - val_acc: 0.9450\n",
      "Epoch 138/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0039 - acc: 0.7981 - val_loss: 0.0068 - val_acc: 0.9496\n",
      "Epoch 139/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7916 - val_loss: 0.0078 - val_acc: 0.9303\n",
      "Epoch 140/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0039 - acc: 0.7987 - val_loss: 0.0068 - val_acc: 0.9538\n",
      "Epoch 141/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0040 - acc: 0.7846 - val_loss: 0.0082 - val_acc: 0.9160\n",
      "Epoch 142/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7874 - val_loss: 0.0067 - val_acc: 0.9548\n",
      "Epoch 143/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0039 - acc: 0.7897 - val_loss: 0.0078 - val_acc: 0.9419\n",
      "Epoch 144/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0039 - acc: 0.7979 - val_loss: 0.0069 - val_acc: 0.9520\n",
      "Epoch 145/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7991 - val_loss: 0.0079 - val_acc: 0.9425\n",
      "Epoch 146/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7984 - val_loss: 0.0069 - val_acc: 0.9537\n",
      "Epoch 147/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0039 - acc: 0.7922 - val_loss: 0.0078 - val_acc: 0.9223\n",
      "Epoch 148/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7879 - val_loss: 0.0066 - val_acc: 0.9550\n",
      "Epoch 149/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7782 - val_loss: 0.0079 - val_acc: 0.9341\n",
      "Epoch 150/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0039 - acc: 0.7966 - val_loss: 0.0068 - val_acc: 0.9520\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Training DNN with 150 iterations, fold 3\n",
      "Train on 28506 samples, validate on 7127 samples\n",
      "Epoch 1/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0038 - acc: 0.7923 - val_loss: 0.0076 - val_acc: 0.9360\n",
      "Epoch 2/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0039 - acc: 0.7954 - val_loss: 0.0069 - val_acc: 0.9513\n",
      "Epoch 3/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7905 - val_loss: 0.0080 - val_acc: 0.9269\n",
      "Epoch 4/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7892 - val_loss: 0.0066 - val_acc: 0.9554\n",
      "Epoch 5/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0039 - acc: 0.7836 - val_loss: 0.0079 - val_acc: 0.9327\n",
      "Epoch 6/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0038 - acc: 0.7971 - val_loss: 0.0069 - val_acc: 0.9529\n",
      "Epoch 7/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0038 - acc: 0.7934 - val_loss: 0.0078 - val_acc: 0.9332\n",
      "Epoch 8/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7974 - val_loss: 0.0069 - val_acc: 0.9515\n",
      "Epoch 9/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7981 - val_loss: 0.0077 - val_acc: 0.9454\n",
      "Epoch 10/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7994 - val_loss: 0.0068 - val_acc: 0.9526\n",
      "Epoch 11/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0039 - acc: 0.7851 - val_loss: 0.0086 - val_acc: 0.8915\n",
      "Epoch 12/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.7876 - val_loss: 0.0068 - val_acc: 0.9544\n",
      "Epoch 13/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0038 - acc: 0.7894 - val_loss: 0.0075 - val_acc: 0.9371\n",
      "Epoch 14/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0038 - acc: 0.8010 - val_loss: 0.0069 - val_acc: 0.9524\n",
      "Epoch 15/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0039 - acc: 0.7937 - val_loss: 0.0076 - val_acc: 0.9416\n",
      "Epoch 16/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7974 - val_loss: 0.0069 - val_acc: 0.9499\n",
      "Epoch 17/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0038 - acc: 0.7897 - val_loss: 0.0085 - val_acc: 0.8948\n",
      "Epoch 18/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7822 - val_loss: 0.0067 - val_acc: 0.9540\n",
      "Epoch 19/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7909 - val_loss: 0.0076 - val_acc: 0.9343\n",
      "Epoch 20/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0038 - acc: 0.7971 - val_loss: 0.0069 - val_acc: 0.9489\n",
      "Epoch 21/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0038 - acc: 0.7941 - val_loss: 0.0075 - val_acc: 0.9363\n",
      "Epoch 22/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0038 - acc: 0.7961 - val_loss: 0.0070 - val_acc: 0.9516\n",
      "Epoch 23/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0038 - acc: 0.7923 - val_loss: 0.0074 - val_acc: 0.9369\n",
      "Epoch 24/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0038 - acc: 0.8013 - val_loss: 0.0068 - val_acc: 0.9534\n",
      "Epoch 25/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0040 - acc: 0.7806 - val_loss: 0.0087 - val_acc: 0.9015\n",
      "Epoch 26/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0039 - acc: 0.7851 - val_loss: 0.0068 - val_acc: 0.9529\n",
      "Epoch 27/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0037 - acc: 0.7944 - val_loss: 0.0075 - val_acc: 0.9421\n",
      "Epoch 28/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7979 - val_loss: 0.0068 - val_acc: 0.9496\n",
      "Epoch 29/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0038 - acc: 0.7906 - val_loss: 0.0078 - val_acc: 0.9199\n",
      "Epoch 30/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0038 - acc: 0.7991 - val_loss: 0.0067 - val_acc: 0.9531\n",
      "Epoch 31/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0038 - acc: 0.7877 - val_loss: 0.0081 - val_acc: 0.9196\n",
      "Epoch 32/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0039 - acc: 0.7921 - val_loss: 0.0067 - val_acc: 0.9543\n",
      "Epoch 33/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0038 - acc: 0.7867 - val_loss: 0.0077 - val_acc: 0.9348\n",
      "Epoch 34/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7956 - val_loss: 0.0068 - val_acc: 0.9524\n",
      "Epoch 35/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7867 - val_loss: 0.0078 - val_acc: 0.9155\n",
      "Epoch 36/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0038 - acc: 0.7926 - val_loss: 0.0067 - val_acc: 0.9523\n",
      "Epoch 37/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0038 - acc: 0.7879 - val_loss: 0.0078 - val_acc: 0.9362\n",
      "Epoch 38/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7985 - val_loss: 0.0067 - val_acc: 0.9516\n",
      "Epoch 39/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0038 - acc: 0.7918 - val_loss: 0.0079 - val_acc: 0.9158\n",
      "Epoch 40/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0038 - acc: 0.7949 - val_loss: 0.0067 - val_acc: 0.9538\n",
      "Epoch 41/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0037 - acc: 0.7862 - val_loss: 0.0075 - val_acc: 0.9348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0037 - acc: 0.8002 - val_loss: 0.0071 - val_acc: 0.9413\n",
      "Epoch 43/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7965 - val_loss: 0.0071 - val_acc: 0.9457\n",
      "Epoch 44/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0038 - acc: 0.7928 - val_loss: 0.0085 - val_acc: 0.8914\n",
      "Epoch 45/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0040 - acc: 0.7816 - val_loss: 0.0066 - val_acc: 0.9536\n",
      "Epoch 46/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.7872 - val_loss: 0.0076 - val_acc: 0.9338\n",
      "Epoch 47/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.8008 - val_loss: 0.0069 - val_acc: 0.9440\n",
      "Epoch 48/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0037 - acc: 0.8013 - val_loss: 0.0076 - val_acc: 0.9371\n",
      "Epoch 49/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7982 - val_loss: 0.0067 - val_acc: 0.9520\n",
      "Epoch 50/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7872 - val_loss: 0.0079 - val_acc: 0.9174\n",
      "Epoch 51/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7919 - val_loss: 0.0067 - val_acc: 0.9527\n",
      "Epoch 52/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7847 - val_loss: 0.0076 - val_acc: 0.9269\n",
      "Epoch 53/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0037 - acc: 0.7993 - val_loss: 0.0068 - val_acc: 0.9503\n",
      "Epoch 54/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0038 - acc: 0.7927 - val_loss: 0.0078 - val_acc: 0.9220\n",
      "Epoch 55/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7953 - val_loss: 0.0067 - val_acc: 0.9505\n",
      "Epoch 56/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.7895 - val_loss: 0.0077 - val_acc: 0.9238\n",
      "Epoch 57/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.7974 - val_loss: 0.0067 - val_acc: 0.9513\n",
      "Epoch 58/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0037 - acc: 0.7884 - val_loss: 0.0081 - val_acc: 0.9143\n",
      "Epoch 59/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7908 - val_loss: 0.0066 - val_acc: 0.9536\n",
      "Epoch 60/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0037 - acc: 0.7869 - val_loss: 0.0077 - val_acc: 0.9272\n",
      "Epoch 61/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.7965 - val_loss: 0.0068 - val_acc: 0.9484\n",
      "Epoch 62/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.7936 - val_loss: 0.0077 - val_acc: 0.9266\n",
      "Epoch 63/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7977 - val_loss: 0.0067 - val_acc: 0.9529\n",
      "Epoch 64/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7892 - val_loss: 0.0079 - val_acc: 0.9158\n",
      "Epoch 65/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0038 - acc: 0.7929 - val_loss: 0.0066 - val_acc: 0.9513\n",
      "Epoch 66/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0038 - acc: 0.7856 - val_loss: 0.0077 - val_acc: 0.9328\n",
      "Epoch 67/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7983 - val_loss: 0.0069 - val_acc: 0.9435\n",
      "Epoch 68/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.8006 - val_loss: 0.0074 - val_acc: 0.9360\n",
      "Epoch 69/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.8017 - val_loss: 0.0071 - val_acc: 0.9371\n",
      "Epoch 70/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.8031 - val_loss: 0.0074 - val_acc: 0.9426\n",
      "Epoch 71/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7999 - val_loss: 0.0069 - val_acc: 0.9346\n",
      "Epoch 72/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.8006 - val_loss: 0.0079 - val_acc: 0.9130\n",
      "Epoch 73/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0039 - acc: 0.7819 - val_loss: 0.0065 - val_acc: 0.9544\n",
      "Epoch 74/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0037 - acc: 0.7780 - val_loss: 0.0074 - val_acc: 0.9334\n",
      "Epoch 75/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.7995 - val_loss: 0.0068 - val_acc: 0.9454\n",
      "Epoch 76/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.7983 - val_loss: 0.0074 - val_acc: 0.9360\n",
      "Epoch 77/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0036 - acc: 0.8024 - val_loss: 0.0067 - val_acc: 0.9423\n",
      "Epoch 78/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.7953 - val_loss: 0.0082 - val_acc: 0.9098\n",
      "Epoch 79/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0038 - acc: 0.7920 - val_loss: 0.0066 - val_acc: 0.9510\n",
      "Epoch 80/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0037 - acc: 0.7899 - val_loss: 0.0077 - val_acc: 0.9147\n",
      "Epoch 81/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.7973 - val_loss: 0.0067 - val_acc: 0.9496\n",
      "Epoch 82/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0037 - acc: 0.7918 - val_loss: 0.0079 - val_acc: 0.9014\n",
      "Epoch 83/150\n",
      "28506/28506 [==============================] - 1s 20us/step - loss: 0.0038 - acc: 0.7932 - val_loss: 0.0068 - val_acc: 0.9503\n",
      "Epoch 84/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7956 - val_loss: 0.0076 - val_acc: 0.9338\n",
      "Epoch 85/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.7991 - val_loss: 0.0066 - val_acc: 0.9485\n",
      "Epoch 86/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.7890 - val_loss: 0.0080 - val_acc: 0.9110\n",
      "Epoch 87/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.7985 - val_loss: 0.0066 - val_acc: 0.9508\n",
      "Epoch 88/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7878 - val_loss: 0.0077 - val_acc: 0.9153\n",
      "Epoch 89/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7991 - val_loss: 0.0067 - val_acc: 0.9489\n",
      "Epoch 90/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7926 - val_loss: 0.0078 - val_acc: 0.9153\n",
      "Epoch 91/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7954 - val_loss: 0.0066 - val_acc: 0.9502\n",
      "Epoch 92/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7879 - val_loss: 0.0078 - val_acc: 0.9092\n",
      "Epoch 93/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7940 - val_loss: 0.0066 - val_acc: 0.9493\n",
      "Epoch 94/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0037 - acc: 0.7893 - val_loss: 0.0076 - val_acc: 0.9283\n",
      "Epoch 95/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0036 - acc: 0.7975 - val_loss: 0.0067 - val_acc: 0.9489\n",
      "Epoch 96/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7941 - val_loss: 0.0078 - val_acc: 0.9217\n",
      "Epoch 97/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7977 - val_loss: 0.0067 - val_acc: 0.9464\n",
      "Epoch 98/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.7936 - val_loss: 0.0076 - val_acc: 0.9136\n",
      "Epoch 99/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.7990 - val_loss: 0.0066 - val_acc: 0.9470\n",
      "Epoch 100/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.7897 - val_loss: 0.0079 - val_acc: 0.9136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0037 - acc: 0.7965 - val_loss: 0.0068 - val_acc: 0.9493\n",
      "Epoch 102/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0036 - acc: 0.7928 - val_loss: 0.0074 - val_acc: 0.9248\n",
      "Epoch 103/150\n",
      "28506/28506 [==============================] - 1s 21us/step - loss: 0.0036 - acc: 0.7989 - val_loss: 0.0068 - val_acc: 0.9524\n",
      "Epoch 104/150\n",
      "28506/28506 [==============================] - 1s 26us/step - loss: 0.0037 - acc: 0.7835 - val_loss: 0.0079 - val_acc: 0.9063\n",
      "Epoch 105/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7926 - val_loss: 0.0065 - val_acc: 0.9510\n",
      "Epoch 106/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0036 - acc: 0.7923 - val_loss: 0.0076 - val_acc: 0.9305\n",
      "Epoch 107/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.8040 - val_loss: 0.0068 - val_acc: 0.9381\n",
      "Epoch 108/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.8040 - val_loss: 0.0074 - val_acc: 0.9423\n",
      "Epoch 109/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0036 - acc: 0.7979 - val_loss: 0.0072 - val_acc: 0.9244\n",
      "Epoch 110/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0036 - acc: 0.8015 - val_loss: 0.0068 - val_acc: 0.9457\n",
      "Epoch 111/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0036 - acc: 0.7896 - val_loss: 0.0082 - val_acc: 0.8893\n",
      "Epoch 112/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0038 - acc: 0.7824 - val_loss: 0.0066 - val_acc: 0.9540\n",
      "Epoch 113/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0036 - acc: 0.7865 - val_loss: 0.0074 - val_acc: 0.9225\n",
      "Epoch 114/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.8013 - val_loss: 0.0067 - val_acc: 0.9411\n",
      "Epoch 115/150\n",
      "28506/28506 [==============================] - 1s 22us/step - loss: 0.0036 - acc: 0.7982 - val_loss: 0.0076 - val_acc: 0.9196\n",
      "Epoch 116/150\n",
      "28506/28506 [==============================] - 1s 22us/step - loss: 0.0036 - acc: 0.7986 - val_loss: 0.0067 - val_acc: 0.9470\n",
      "Epoch 117/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0036 - acc: 0.7934 - val_loss: 0.0076 - val_acc: 0.9218\n",
      "Epoch 118/150\n",
      "28506/28506 [==============================] - 1s 22us/step - loss: 0.0036 - acc: 0.8017 - val_loss: 0.0067 - val_acc: 0.9446\n",
      "Epoch 119/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0036 - acc: 0.7917 - val_loss: 0.0077 - val_acc: 0.9078\n",
      "Epoch 120/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.7944 - val_loss: 0.0066 - val_acc: 0.9536\n",
      "Epoch 121/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7853 - val_loss: 0.0075 - val_acc: 0.9214\n",
      "Epoch 122/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0035 - acc: 0.8000 - val_loss: 0.0066 - val_acc: 0.9478\n",
      "Epoch 123/150\n",
      "28506/28506 [==============================] - 1s 26us/step - loss: 0.0036 - acc: 0.7910 - val_loss: 0.0079 - val_acc: 0.9046\n",
      "Epoch 124/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0037 - acc: 0.7922 - val_loss: 0.0067 - val_acc: 0.9488\n",
      "Epoch 125/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0036 - acc: 0.7946 - val_loss: 0.0073 - val_acc: 0.9317\n",
      "Epoch 126/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.8014 - val_loss: 0.0069 - val_acc: 0.9401\n",
      "Epoch 127/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0035 - acc: 0.8009 - val_loss: 0.0076 - val_acc: 0.9176\n",
      "Epoch 128/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0036 - acc: 0.7940 - val_loss: 0.0065 - val_acc: 0.9526\n",
      "Epoch 129/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0036 - acc: 0.7810 - val_loss: 0.0076 - val_acc: 0.9109\n",
      "Epoch 130/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0036 - acc: 0.8005 - val_loss: 0.0067 - val_acc: 0.9449\n",
      "Epoch 131/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0035 - acc: 0.7957 - val_loss: 0.0076 - val_acc: 0.9258\n",
      "Epoch 132/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0036 - acc: 0.7975 - val_loss: 0.0068 - val_acc: 0.9398\n",
      "Epoch 133/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.7971 - val_loss: 0.0074 - val_acc: 0.9218\n",
      "Epoch 134/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.7998 - val_loss: 0.0066 - val_acc: 0.9537\n",
      "Epoch 135/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7795 - val_loss: 0.0080 - val_acc: 0.8997\n",
      "Epoch 136/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0036 - acc: 0.7915 - val_loss: 0.0066 - val_acc: 0.9477\n",
      "Epoch 137/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0035 - acc: 0.7965 - val_loss: 0.0075 - val_acc: 0.9270\n",
      "Epoch 138/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.8019 - val_loss: 0.0067 - val_acc: 0.9421\n",
      "Epoch 139/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.8004 - val_loss: 0.0073 - val_acc: 0.9248\n",
      "Epoch 140/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.8069 - val_loss: 0.0066 - val_acc: 0.9467\n",
      "Epoch 141/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0036 - acc: 0.7879 - val_loss: 0.0079 - val_acc: 0.8942\n",
      "Epoch 142/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7920 - val_loss: 0.0065 - val_acc: 0.9506\n",
      "Epoch 143/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.7905 - val_loss: 0.0077 - val_acc: 0.9240\n",
      "Epoch 144/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0035 - acc: 0.8003 - val_loss: 0.0067 - val_acc: 0.9384\n",
      "Epoch 145/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0035 - acc: 0.8008 - val_loss: 0.0075 - val_acc: 0.9206\n",
      "Epoch 146/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7972 - val_loss: 0.0066 - val_acc: 0.9474\n",
      "Epoch 147/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0036 - acc: 0.7893 - val_loss: 0.0075 - val_acc: 0.9144\n",
      "Epoch 148/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.8037 - val_loss: 0.0066 - val_acc: 0.9453\n",
      "Epoch 149/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.7932 - val_loss: 0.0078 - val_acc: 0.9122\n",
      "Epoch 150/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0036 - acc: 0.7998 - val_loss: 0.0068 - val_acc: 0.9404\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Training DNN with 150 iterations, fold 4\n",
      "Train on 28506 samples, validate on 7127 samples\n",
      "Epoch 1/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.7958 - val_loss: 0.0072 - val_acc: 0.9270\n",
      "Epoch 2/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.7977 - val_loss: 0.0073 - val_acc: 0.9211\n",
      "Epoch 3/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0036 - acc: 0.7962 - val_loss: 0.0065 - val_acc: 0.9499\n",
      "Epoch 4/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.7818 - val_loss: 0.0078 - val_acc: 0.9016\n",
      "Epoch 5/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0035 - acc: 0.7991 - val_loss: 0.0066 - val_acc: 0.9460\n",
      "Epoch 6/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.7949 - val_loss: 0.0074 - val_acc: 0.9087\n",
      "Epoch 7/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7991 - val_loss: 0.0068 - val_acc: 0.9429\n",
      "Epoch 8/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.7900 - val_loss: 0.0075 - val_acc: 0.9217\n",
      "Epoch 9/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.8009 - val_loss: 0.0065 - val_acc: 0.9439\n",
      "Epoch 10/150\n",
      "28506/28506 [==============================] - 1s 20us/step - loss: 0.0036 - acc: 0.7910 - val_loss: 0.0078 - val_acc: 0.9066\n",
      "Epoch 11/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0035 - acc: 0.8011 - val_loss: 0.0068 - val_acc: 0.9315\n",
      "Epoch 12/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.8000 - val_loss: 0.0071 - val_acc: 0.9394\n",
      "Epoch 13/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7952 - val_loss: 0.0074 - val_acc: 0.8990\n",
      "Epoch 14/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0036 - acc: 0.7970 - val_loss: 0.0064 - val_acc: 0.9509\n",
      "Epoch 15/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0036 - acc: 0.7813 - val_loss: 0.0078 - val_acc: 0.9001\n",
      "Epoch 16/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7979 - val_loss: 0.0067 - val_acc: 0.9442\n",
      "Epoch 17/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7967 - val_loss: 0.0073 - val_acc: 0.9119\n",
      "Epoch 18/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0035 - acc: 0.8020 - val_loss: 0.0068 - val_acc: 0.9453\n",
      "Epoch 19/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0035 - acc: 0.7931 - val_loss: 0.0070 - val_acc: 0.9230\n",
      "Epoch 20/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0035 - acc: 0.7997 - val_loss: 0.0075 - val_acc: 0.9162\n",
      "Epoch 21/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0036 - acc: 0.7915 - val_loss: 0.0064 - val_acc: 0.9522\n",
      "Epoch 22/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0035 - acc: 0.7826 - val_loss: 0.0076 - val_acc: 0.9096\n",
      "Epoch 23/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0035 - acc: 0.8001 - val_loss: 0.0067 - val_acc: 0.9378\n",
      "Epoch 24/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.8030 - val_loss: 0.0074 - val_acc: 0.9282\n",
      "Epoch 25/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.8023 - val_loss: 0.0066 - val_acc: 0.9374\n",
      "Epoch 26/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7971 - val_loss: 0.0077 - val_acc: 0.8965\n",
      "Epoch 27/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7980 - val_loss: 0.0065 - val_acc: 0.9493\n",
      "Epoch 28/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0035 - acc: 0.7820 - val_loss: 0.0076 - val_acc: 0.8932\n",
      "Epoch 29/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.7986 - val_loss: 0.0066 - val_acc: 0.9449\n",
      "Epoch 30/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.7942 - val_loss: 0.0076 - val_acc: 0.9137\n",
      "Epoch 31/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.8029 - val_loss: 0.0067 - val_acc: 0.9343\n",
      "Epoch 32/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7992 - val_loss: 0.0073 - val_acc: 0.9218\n",
      "Epoch 33/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7979 - val_loss: 0.0067 - val_acc: 0.9369\n",
      "Epoch 34/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7936 - val_loss: 0.0075 - val_acc: 0.8970\n",
      "Epoch 35/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7989 - val_loss: 0.0065 - val_acc: 0.9475\n",
      "Epoch 36/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.7878 - val_loss: 0.0078 - val_acc: 0.9021\n",
      "Epoch 37/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.7998 - val_loss: 0.0066 - val_acc: 0.9475\n",
      "Epoch 38/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7848 - val_loss: 0.0074 - val_acc: 0.8988\n",
      "Epoch 39/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.8039 - val_loss: 0.0067 - val_acc: 0.9437\n",
      "Epoch 40/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7984 - val_loss: 0.0074 - val_acc: 0.9115\n",
      "Epoch 41/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.8028 - val_loss: 0.0067 - val_acc: 0.9409\n",
      "Epoch 42/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7963 - val_loss: 0.0078 - val_acc: 0.9036\n",
      "Epoch 43/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0035 - acc: 0.7945 - val_loss: 0.0065 - val_acc: 0.9437\n",
      "Epoch 44/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7879 - val_loss: 0.0075 - val_acc: 0.9064\n",
      "Epoch 45/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.8039 - val_loss: 0.0067 - val_acc: 0.9409\n",
      "Epoch 46/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7917 - val_loss: 0.0075 - val_acc: 0.9042\n",
      "Epoch 47/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7998 - val_loss: 0.0066 - val_acc: 0.9442\n",
      "Epoch 48/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7912 - val_loss: 0.0077 - val_acc: 0.8950\n",
      "Epoch 49/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7961 - val_loss: 0.0066 - val_acc: 0.9447\n",
      "Epoch 50/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7911 - val_loss: 0.0076 - val_acc: 0.8859\n",
      "Epoch 51/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7972 - val_loss: 0.0066 - val_acc: 0.9416\n",
      "Epoch 52/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7966 - val_loss: 0.0075 - val_acc: 0.9241\n",
      "Epoch 53/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.8025 - val_loss: 0.0068 - val_acc: 0.9234\n",
      "Epoch 54/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.8063 - val_loss: 0.0075 - val_acc: 0.9008\n",
      "Epoch 55/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7948 - val_loss: 0.0065 - val_acc: 0.9502\n",
      "Epoch 56/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7863 - val_loss: 0.0075 - val_acc: 0.9040\n",
      "Epoch 57/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.8051 - val_loss: 0.0065 - val_acc: 0.9406\n",
      "Epoch 58/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0034 - acc: 0.7992 - val_loss: 0.0076 - val_acc: 0.9089\n",
      "Epoch 59/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7979 - val_loss: 0.0066 - val_acc: 0.9383\n",
      "Epoch 60/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7947 - val_loss: 0.0074 - val_acc: 0.9050\n",
      "Epoch 61/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.8033 - val_loss: 0.0067 - val_acc: 0.9492\n",
      "Epoch 62/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7822 - val_loss: 0.0078 - val_acc: 0.8760\n",
      "Epoch 63/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0035 - acc: 0.7920 - val_loss: 0.0065 - val_acc: 0.9426\n",
      "Epoch 64/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7925 - val_loss: 0.0076 - val_acc: 0.9106\n",
      "Epoch 65/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.8008 - val_loss: 0.0067 - val_acc: 0.9314\n",
      "Epoch 66/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.8015 - val_loss: 0.0071 - val_acc: 0.9217\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0033 - acc: 0.8051 - val_loss: 0.0070 - val_acc: 0.9258\n",
      "Epoch 68/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0034 - acc: 0.8005 - val_loss: 0.0069 - val_acc: 0.9290\n",
      "Epoch 69/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7987 - val_loss: 0.0079 - val_acc: 0.8838\n",
      "Epoch 70/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0035 - acc: 0.7913 - val_loss: 0.0064 - val_acc: 0.9513\n",
      "Epoch 71/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0034 - acc: 0.7803 - val_loss: 0.0076 - val_acc: 0.8983\n",
      "Epoch 72/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8004 - val_loss: 0.0066 - val_acc: 0.9345\n",
      "Epoch 73/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8032 - val_loss: 0.0074 - val_acc: 0.9157\n",
      "Epoch 74/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.8020 - val_loss: 0.0067 - val_acc: 0.9315\n",
      "Epoch 75/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7996 - val_loss: 0.0072 - val_acc: 0.8945\n",
      "Epoch 76/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.8019 - val_loss: 0.0066 - val_acc: 0.9482\n",
      "Epoch 77/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7857 - val_loss: 0.0080 - val_acc: 0.8799\n",
      "Epoch 78/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7932 - val_loss: 0.0065 - val_acc: 0.9412\n",
      "Epoch 79/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7953 - val_loss: 0.0076 - val_acc: 0.9130\n",
      "Epoch 80/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0034 - acc: 0.8003 - val_loss: 0.0067 - val_acc: 0.9291\n",
      "Epoch 81/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0033 - acc: 0.8021 - val_loss: 0.0071 - val_acc: 0.9165\n",
      "Epoch 82/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8055 - val_loss: 0.0072 - val_acc: 0.9265\n",
      "Epoch 83/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8037 - val_loss: 0.0067 - val_acc: 0.9275\n",
      "Epoch 84/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0033 - acc: 0.8029 - val_loss: 0.0077 - val_acc: 0.8865\n",
      "Epoch 85/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7902 - val_loss: 0.0064 - val_acc: 0.9503\n",
      "Epoch 86/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7818 - val_loss: 0.0076 - val_acc: 0.8979\n",
      "Epoch 87/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7995 - val_loss: 0.0067 - val_acc: 0.9388\n",
      "Epoch 88/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0033 - acc: 0.7955 - val_loss: 0.0073 - val_acc: 0.9056\n",
      "Epoch 89/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0033 - acc: 0.8043 - val_loss: 0.0067 - val_acc: 0.9376\n",
      "Epoch 90/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0033 - acc: 0.7939 - val_loss: 0.0077 - val_acc: 0.8824\n",
      "Epoch 91/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7956 - val_loss: 0.0065 - val_acc: 0.9442\n",
      "Epoch 92/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7892 - val_loss: 0.0077 - val_acc: 0.8956\n",
      "Epoch 93/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7957 - val_loss: 0.0066 - val_acc: 0.9363\n",
      "Epoch 94/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7973 - val_loss: 0.0074 - val_acc: 0.9054\n",
      "Epoch 95/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8028 - val_loss: 0.0067 - val_acc: 0.9408\n",
      "Epoch 96/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7948 - val_loss: 0.0075 - val_acc: 0.8934\n",
      "Epoch 97/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8047 - val_loss: 0.0066 - val_acc: 0.9373\n",
      "Epoch 98/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7961 - val_loss: 0.0079 - val_acc: 0.8904\n",
      "Epoch 99/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7936 - val_loss: 0.0065 - val_acc: 0.9435\n",
      "Epoch 100/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7922 - val_loss: 0.0076 - val_acc: 0.8938\n",
      "Epoch 101/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8006 - val_loss: 0.0068 - val_acc: 0.9376\n",
      "Epoch 102/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7963 - val_loss: 0.0072 - val_acc: 0.9047\n",
      "Epoch 103/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8010 - val_loss: 0.0067 - val_acc: 0.9378\n",
      "Epoch 104/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7956 - val_loss: 0.0077 - val_acc: 0.8879\n",
      "Epoch 105/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7954 - val_loss: 0.0064 - val_acc: 0.9449\n",
      "Epoch 106/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7925 - val_loss: 0.0075 - val_acc: 0.8965\n",
      "Epoch 107/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8033 - val_loss: 0.0067 - val_acc: 0.9423\n",
      "Epoch 108/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7939 - val_loss: 0.0071 - val_acc: 0.9165\n",
      "Epoch 109/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8055 - val_loss: 0.0072 - val_acc: 0.9091\n",
      "Epoch 110/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8023 - val_loss: 0.0067 - val_acc: 0.9399\n",
      "Epoch 111/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0033 - acc: 0.7934 - val_loss: 0.0079 - val_acc: 0.8838\n",
      "Epoch 112/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0034 - acc: 0.7954 - val_loss: 0.0065 - val_acc: 0.9405\n",
      "Epoch 113/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0033 - acc: 0.7915 - val_loss: 0.0076 - val_acc: 0.8883\n",
      "Epoch 114/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0033 - acc: 0.8033 - val_loss: 0.0067 - val_acc: 0.9394\n",
      "Epoch 115/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7977 - val_loss: 0.0072 - val_acc: 0.8938\n",
      "Epoch 116/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8053 - val_loss: 0.0069 - val_acc: 0.9395\n",
      "Epoch 117/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7965 - val_loss: 0.0070 - val_acc: 0.9171\n",
      "Epoch 118/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8023 - val_loss: 0.0075 - val_acc: 0.8908\n",
      "Epoch 119/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7902 - val_loss: 0.0064 - val_acc: 0.9493\n",
      "Epoch 120/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7817 - val_loss: 0.0075 - val_acc: 0.8931\n",
      "Epoch 121/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8024 - val_loss: 0.0066 - val_acc: 0.9327\n",
      "Epoch 122/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8019 - val_loss: 0.0073 - val_acc: 0.9137\n",
      "Epoch 123/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8046 - val_loss: 0.0068 - val_acc: 0.9287\n",
      "Epoch 124/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8034 - val_loss: 0.0070 - val_acc: 0.9133\n",
      "Epoch 125/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8046 - val_loss: 0.0072 - val_acc: 0.9207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0033 - acc: 0.8041 - val_loss: 0.0064 - val_acc: 0.9451\n",
      "Epoch 127/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0035 - acc: 0.7724 - val_loss: 0.0078 - val_acc: 0.8824\n",
      "Epoch 128/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7975 - val_loss: 0.0066 - val_acc: 0.9374\n",
      "Epoch 129/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7949 - val_loss: 0.0073 - val_acc: 0.8925\n",
      "Epoch 130/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8048 - val_loss: 0.0068 - val_acc: 0.9402\n",
      "Epoch 131/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7939 - val_loss: 0.0074 - val_acc: 0.8935\n",
      "Epoch 132/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8027 - val_loss: 0.0065 - val_acc: 0.9397\n",
      "Epoch 133/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0034 - acc: 0.7903 - val_loss: 0.0076 - val_acc: 0.8976\n",
      "Epoch 134/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8021 - val_loss: 0.0065 - val_acc: 0.9359\n",
      "Epoch 135/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0033 - acc: 0.7933 - val_loss: 0.0077 - val_acc: 0.8929\n",
      "Epoch 136/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0033 - acc: 0.8011 - val_loss: 0.0067 - val_acc: 0.9321\n",
      "Epoch 137/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7993 - val_loss: 0.0072 - val_acc: 0.9143\n",
      "Epoch 138/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8034 - val_loss: 0.0069 - val_acc: 0.9211\n",
      "Epoch 139/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0032 - acc: 0.8018 - val_loss: 0.0073 - val_acc: 0.9044\n",
      "Epoch 140/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8025 - val_loss: 0.0066 - val_acc: 0.9353\n",
      "Epoch 141/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7865 - val_loss: 0.0082 - val_acc: 0.8469\n",
      "Epoch 142/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0033 - acc: 0.7880 - val_loss: 0.0066 - val_acc: 0.9397\n",
      "Epoch 143/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7959 - val_loss: 0.0074 - val_acc: 0.8957\n",
      "Epoch 144/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8026 - val_loss: 0.0067 - val_acc: 0.9311\n",
      "Epoch 145/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8043 - val_loss: 0.0072 - val_acc: 0.9113\n",
      "Epoch 146/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8049 - val_loss: 0.0066 - val_acc: 0.9268\n",
      "Epoch 147/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0033 - acc: 0.7946 - val_loss: 0.0081 - val_acc: 0.8767\n",
      "Epoch 148/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0033 - acc: 0.7940 - val_loss: 0.0065 - val_acc: 0.9428\n",
      "Epoch 149/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7907 - val_loss: 0.0074 - val_acc: 0.8974\n",
      "Epoch 150/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8056 - val_loss: 0.0067 - val_acc: 0.9390\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Training DNN with 150 iterations, fold 5\n",
      "Train on 28506 samples, validate on 7127 samples\n",
      "Epoch 1/150\n",
      "28506/28506 [==============================] - 0s 12us/step - loss: 0.0033 - acc: 0.7965 - val_loss: 0.0075 - val_acc: 0.8833\n",
      "Epoch 2/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0033 - acc: 0.7939 - val_loss: 0.0066 - val_acc: 0.9475\n",
      "Epoch 3/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7866 - val_loss: 0.0076 - val_acc: 0.9005\n",
      "Epoch 4/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0034 - acc: 0.7963 - val_loss: 0.0065 - val_acc: 0.9369\n",
      "Epoch 5/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8001 - val_loss: 0.0074 - val_acc: 0.9092\n",
      "Epoch 6/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8055 - val_loss: 0.0065 - val_acc: 0.9429\n",
      "Epoch 7/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0033 - acc: 0.7936 - val_loss: 0.0075 - val_acc: 0.8872\n",
      "Epoch 8/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8010 - val_loss: 0.0066 - val_acc: 0.9402\n",
      "Epoch 9/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7976 - val_loss: 0.0073 - val_acc: 0.9151\n",
      "Epoch 10/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8026 - val_loss: 0.0066 - val_acc: 0.9384\n",
      "Epoch 11/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7925 - val_loss: 0.0076 - val_acc: 0.8977\n",
      "Epoch 12/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7957 - val_loss: 0.0065 - val_acc: 0.9456\n",
      "Epoch 13/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0033 - acc: 0.7887 - val_loss: 0.0075 - val_acc: 0.8960\n",
      "Epoch 14/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8012 - val_loss: 0.0066 - val_acc: 0.9451\n",
      "Epoch 15/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7893 - val_loss: 0.0074 - val_acc: 0.9122\n",
      "Epoch 16/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0033 - acc: 0.8014 - val_loss: 0.0066 - val_acc: 0.9322\n",
      "Epoch 17/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8019 - val_loss: 0.0073 - val_acc: 0.9131\n",
      "Epoch 18/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.8035 - val_loss: 0.0064 - val_acc: 0.9453\n",
      "Epoch 19/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7863 - val_loss: 0.0075 - val_acc: 0.8929\n",
      "Epoch 20/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.8006 - val_loss: 0.0065 - val_acc: 0.9412\n",
      "Epoch 21/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.7959 - val_loss: 0.0073 - val_acc: 0.9158\n",
      "Epoch 22/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8006 - val_loss: 0.0068 - val_acc: 0.9241\n",
      "Epoch 23/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.8068 - val_loss: 0.0068 - val_acc: 0.9419\n",
      "Epoch 24/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7918 - val_loss: 0.0075 - val_acc: 0.8730\n",
      "Epoch 25/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0034 - acc: 0.7877 - val_loss: 0.0064 - val_acc: 0.9488\n",
      "Epoch 26/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7924 - val_loss: 0.0075 - val_acc: 0.9106\n",
      "Epoch 27/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8053 - val_loss: 0.0066 - val_acc: 0.9373\n",
      "Epoch 28/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7994 - val_loss: 0.0073 - val_acc: 0.8997\n",
      "Epoch 29/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0032 - acc: 0.8048 - val_loss: 0.0066 - val_acc: 0.9411\n",
      "Epoch 30/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0032 - acc: 0.7929 - val_loss: 0.0075 - val_acc: 0.8878\n",
      "Epoch 31/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0033 - acc: 0.8016 - val_loss: 0.0065 - val_acc: 0.9446\n",
      "Epoch 32/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0033 - acc: 0.7938 - val_loss: 0.0074 - val_acc: 0.9103\n",
      "Epoch 33/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0032 - acc: 0.8015 - val_loss: 0.0066 - val_acc: 0.9380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7968 - val_loss: 0.0074 - val_acc: 0.8943\n",
      "Epoch 35/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.8000 - val_loss: 0.0065 - val_acc: 0.9457\n",
      "Epoch 36/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7976 - val_loss: 0.0075 - val_acc: 0.8991\n",
      "Epoch 37/150\n",
      "28506/28506 [==============================] - 1s 19us/step - loss: 0.0033 - acc: 0.8027 - val_loss: 0.0065 - val_acc: 0.9335\n",
      "Epoch 38/150\n",
      "28506/28506 [==============================] - 0s 17us/step - loss: 0.0032 - acc: 0.8014 - val_loss: 0.0074 - val_acc: 0.9101\n",
      "Epoch 39/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8031 - val_loss: 0.0066 - val_acc: 0.9415\n",
      "Epoch 40/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7937 - val_loss: 0.0075 - val_acc: 0.8786\n",
      "Epoch 41/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7973 - val_loss: 0.0065 - val_acc: 0.9484\n",
      "Epoch 42/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.7908 - val_loss: 0.0075 - val_acc: 0.8998\n",
      "Epoch 43/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.7985 - val_loss: 0.0066 - val_acc: 0.9390\n",
      "Epoch 44/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.7991 - val_loss: 0.0073 - val_acc: 0.9136\n",
      "Epoch 45/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8019 - val_loss: 0.0067 - val_acc: 0.9360\n",
      "Epoch 46/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7961 - val_loss: 0.0074 - val_acc: 0.8991\n",
      "Epoch 47/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8014 - val_loss: 0.0065 - val_acc: 0.9428\n",
      "Epoch 48/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.7971 - val_loss: 0.0075 - val_acc: 0.9002\n",
      "Epoch 49/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8030 - val_loss: 0.0064 - val_acc: 0.9428\n",
      "Epoch 50/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7952 - val_loss: 0.0074 - val_acc: 0.8955\n",
      "Epoch 51/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8020 - val_loss: 0.0066 - val_acc: 0.9444\n",
      "Epoch 52/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7921 - val_loss: 0.0072 - val_acc: 0.8967\n",
      "Epoch 53/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8020 - val_loss: 0.0067 - val_acc: 0.9464\n",
      "Epoch 54/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0032 - acc: 0.7907 - val_loss: 0.0073 - val_acc: 0.9039\n",
      "Epoch 55/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0032 - acc: 0.8017 - val_loss: 0.0064 - val_acc: 0.9430\n",
      "Epoch 56/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7955 - val_loss: 0.0076 - val_acc: 0.9008\n",
      "Epoch 57/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.8020 - val_loss: 0.0065 - val_acc: 0.9390\n",
      "Epoch 58/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.7936 - val_loss: 0.0073 - val_acc: 0.9096\n",
      "Epoch 59/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0032 - acc: 0.8031 - val_loss: 0.0068 - val_acc: 0.9254\n",
      "Epoch 60/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8073 - val_loss: 0.0068 - val_acc: 0.9362\n",
      "Epoch 61/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8014 - val_loss: 0.0074 - val_acc: 0.8896\n",
      "Epoch 62/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7983 - val_loss: 0.0064 - val_acc: 0.9470\n",
      "Epoch 63/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7869 - val_loss: 0.0076 - val_acc: 0.8959\n",
      "Epoch 64/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8010 - val_loss: 0.0065 - val_acc: 0.9362\n",
      "Epoch 65/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8021 - val_loss: 0.0074 - val_acc: 0.9037\n",
      "Epoch 66/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8039 - val_loss: 0.0066 - val_acc: 0.9401\n",
      "Epoch 67/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7961 - val_loss: 0.0075 - val_acc: 0.8890\n",
      "Epoch 68/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7987 - val_loss: 0.0066 - val_acc: 0.9413\n",
      "Epoch 69/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7968 - val_loss: 0.0075 - val_acc: 0.9008\n",
      "Epoch 70/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8031 - val_loss: 0.0065 - val_acc: 0.9391\n",
      "Epoch 71/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7964 - val_loss: 0.0075 - val_acc: 0.8986\n",
      "Epoch 72/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.8032 - val_loss: 0.0065 - val_acc: 0.9442\n",
      "Epoch 73/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7963 - val_loss: 0.0073 - val_acc: 0.9044\n",
      "Epoch 74/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8068 - val_loss: 0.0067 - val_acc: 0.9430\n",
      "Epoch 75/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0032 - acc: 0.7926 - val_loss: 0.0071 - val_acc: 0.9070\n",
      "Epoch 76/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8052 - val_loss: 0.0068 - val_acc: 0.9240\n",
      "Epoch 77/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8062 - val_loss: 0.0074 - val_acc: 0.9169\n",
      "Epoch 78/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7971 - val_loss: 0.0064 - val_acc: 0.9470\n",
      "Epoch 79/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0033 - acc: 0.7857 - val_loss: 0.0075 - val_acc: 0.8936\n",
      "Epoch 80/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8049 - val_loss: 0.0065 - val_acc: 0.9401\n",
      "Epoch 81/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7980 - val_loss: 0.0073 - val_acc: 0.9049\n",
      "Epoch 82/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0031 - acc: 0.8081 - val_loss: 0.0066 - val_acc: 0.9327\n",
      "Epoch 83/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0031 - acc: 0.7986 - val_loss: 0.0074 - val_acc: 0.8974\n",
      "Epoch 84/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.7978 - val_loss: 0.0065 - val_acc: 0.9436\n",
      "Epoch 85/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.7940 - val_loss: 0.0078 - val_acc: 0.8806\n",
      "Epoch 86/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7967 - val_loss: 0.0065 - val_acc: 0.9371\n",
      "Epoch 87/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8023 - val_loss: 0.0072 - val_acc: 0.9030\n",
      "Epoch 88/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8056 - val_loss: 0.0066 - val_acc: 0.9397\n",
      "Epoch 89/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7953 - val_loss: 0.0075 - val_acc: 0.8900\n",
      "Epoch 90/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7990 - val_loss: 0.0065 - val_acc: 0.9430\n",
      "Epoch 91/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7975 - val_loss: 0.0075 - val_acc: 0.9087\n",
      "Epoch 92/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8064 - val_loss: 0.0065 - val_acc: 0.9430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7926 - val_loss: 0.0077 - val_acc: 0.8936\n",
      "Epoch 94/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8001 - val_loss: 0.0066 - val_acc: 0.9294\n",
      "Epoch 95/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8047 - val_loss: 0.0072 - val_acc: 0.9221\n",
      "Epoch 96/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8075 - val_loss: 0.0066 - val_acc: 0.9272\n",
      "Epoch 97/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.8029 - val_loss: 0.0076 - val_acc: 0.8879\n",
      "Epoch 98/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7949 - val_loss: 0.0065 - val_acc: 0.9463\n",
      "Epoch 99/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0031 - acc: 0.7965 - val_loss: 0.0073 - val_acc: 0.8981\n",
      "Epoch 100/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8044 - val_loss: 0.0065 - val_acc: 0.9443\n",
      "Epoch 101/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7918 - val_loss: 0.0075 - val_acc: 0.9012\n",
      "Epoch 102/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.8065 - val_loss: 0.0066 - val_acc: 0.9314\n",
      "Epoch 103/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8068 - val_loss: 0.0070 - val_acc: 0.9244\n",
      "Epoch 104/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8048 - val_loss: 0.0071 - val_acc: 0.9087\n",
      "Epoch 105/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8017 - val_loss: 0.0066 - val_acc: 0.9406\n",
      "Epoch 106/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7950 - val_loss: 0.0080 - val_acc: 0.8712\n",
      "Epoch 107/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7921 - val_loss: 0.0065 - val_acc: 0.9387\n",
      "Epoch 108/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0031 - acc: 0.8023 - val_loss: 0.0071 - val_acc: 0.9185\n",
      "Epoch 109/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0030 - acc: 0.8084 - val_loss: 0.0067 - val_acc: 0.9290\n",
      "Epoch 110/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8068 - val_loss: 0.0071 - val_acc: 0.9124\n",
      "Epoch 111/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8090 - val_loss: 0.0067 - val_acc: 0.9380\n",
      "Epoch 112/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7979 - val_loss: 0.0075 - val_acc: 0.8837\n",
      "Epoch 113/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7954 - val_loss: 0.0064 - val_acc: 0.9467\n",
      "Epoch 114/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7889 - val_loss: 0.0073 - val_acc: 0.9071\n",
      "Epoch 115/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0031 - acc: 0.8033 - val_loss: 0.0066 - val_acc: 0.9321\n",
      "Epoch 116/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8003 - val_loss: 0.0071 - val_acc: 0.9070\n",
      "Epoch 117/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8037 - val_loss: 0.0068 - val_acc: 0.9328\n",
      "Epoch 118/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7969 - val_loss: 0.0072 - val_acc: 0.9092\n",
      "Epoch 119/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8088 - val_loss: 0.0066 - val_acc: 0.9360\n",
      "Epoch 120/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0031 - acc: 0.8009 - val_loss: 0.0078 - val_acc: 0.8852\n",
      "Epoch 121/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7965 - val_loss: 0.0064 - val_acc: 0.9446\n",
      "Epoch 122/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7932 - val_loss: 0.0074 - val_acc: 0.8913\n",
      "Epoch 123/150\n",
      "28506/28506 [==============================] - 0s 13us/step - loss: 0.0031 - acc: 0.8031 - val_loss: 0.0067 - val_acc: 0.9409\n",
      "Epoch 124/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0030 - acc: 0.7973 - val_loss: 0.0070 - val_acc: 0.9002\n",
      "Epoch 125/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8074 - val_loss: 0.0068 - val_acc: 0.9380\n",
      "Epoch 126/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0030 - acc: 0.8045 - val_loss: 0.0072 - val_acc: 0.9068\n",
      "Epoch 127/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0031 - acc: 0.8084 - val_loss: 0.0064 - val_acc: 0.9446\n",
      "Epoch 128/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7892 - val_loss: 0.0077 - val_acc: 0.8913\n",
      "Epoch 129/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8064 - val_loss: 0.0065 - val_acc: 0.9391\n",
      "Epoch 130/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7997 - val_loss: 0.0072 - val_acc: 0.9112\n",
      "Epoch 131/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8020 - val_loss: 0.0069 - val_acc: 0.9227\n",
      "Epoch 132/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0030 - acc: 0.8084 - val_loss: 0.0069 - val_acc: 0.9349\n",
      "Epoch 133/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.8026 - val_loss: 0.0072 - val_acc: 0.8925\n",
      "Epoch 134/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0031 - acc: 0.8024 - val_loss: 0.0064 - val_acc: 0.9505\n",
      "Epoch 135/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0032 - acc: 0.7784 - val_loss: 0.0078 - val_acc: 0.8932\n",
      "Epoch 136/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0031 - acc: 0.8067 - val_loss: 0.0065 - val_acc: 0.9331\n",
      "Epoch 137/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0030 - acc: 0.8079 - val_loss: 0.0073 - val_acc: 0.9160\n",
      "Epoch 138/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0030 - acc: 0.8077 - val_loss: 0.0067 - val_acc: 0.9287\n",
      "Epoch 139/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0030 - acc: 0.8068 - val_loss: 0.0070 - val_acc: 0.9182\n",
      "Epoch 140/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0030 - acc: 0.8099 - val_loss: 0.0070 - val_acc: 0.9178\n",
      "Epoch 141/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0030 - acc: 0.8077 - val_loss: 0.0066 - val_acc: 0.9303\n",
      "Epoch 142/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 0.7957 - val_loss: 0.0080 - val_acc: 0.8734\n",
      "Epoch 143/150\n",
      "28506/28506 [==============================] - 0s 14us/step - loss: 0.0031 - acc: 0.7978 - val_loss: 0.0065 - val_acc: 0.9425\n",
      "Epoch 144/150\n",
      "28506/28506 [==============================] - 1s 18us/step - loss: 0.0030 - acc: 0.7974 - val_loss: 0.0073 - val_acc: 0.9042\n",
      "Epoch 145/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0030 - acc: 0.8066 - val_loss: 0.0066 - val_acc: 0.9362\n",
      "Epoch 146/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0030 - acc: 0.8024 - val_loss: 0.0076 - val_acc: 0.8941\n",
      "Epoch 147/150\n",
      "28506/28506 [==============================] - 0s 15us/step - loss: 0.0031 - acc: 0.8021 - val_loss: 0.0066 - val_acc: 0.9392\n",
      "Epoch 148/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0030 - acc: 0.7991 - val_loss: 0.0073 - val_acc: 0.9071\n",
      "Epoch 149/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0030 - acc: 0.8083 - val_loss: 0.0066 - val_acc: 0.9418\n",
      "Epoch 150/150\n",
      "28506/28506 [==============================] - 0s 16us/step - loss: 0.0031 - acc: 0.7956 - val_loss: 0.0076 - val_acc: 0.8903\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Saving Histology blind test outputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hist 72: Input Array Shape (7272, 45)\n",
      "Output Hist 72: Array Shape (7272, 66)\n",
      "Saving Pair Wise Reprod Results on HCP\n",
      "Saving network for this fold\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-4be4dd58a851>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-1f81150da159>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_dir_DNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mnet_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_dir_DNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_model_fold\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mmodel_D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\vishwesh\\anaconda3\\envs\\deep_l_v2\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   2578\u001b[0m         \"\"\"\n\u001b[0;32m   2579\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2580\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2582\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\vishwesh\\anaconda3\\envs\\deep_l_v2\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`save_model` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_json_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_l",
   "language": "python",
   "name": "deep_l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
