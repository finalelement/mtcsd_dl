{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Vishwesh\\Anaconda3\\envs\\deep_l\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat, savemat\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from keras.optimizers import SGD, adam, nadam, Adagrad\n",
    "from keras.regularizers import l1,l2\n",
    "\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "from keras.losses import mean_squared_logarithmic_error\n",
    "\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8584910759355202278\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5073253171\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 4362147803954039779\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acc_loss(y_true, y_pred):\n",
    "    \n",
    "    # Subtract mean value from expansions of true and pred\n",
    "    x_true = y_true[:,1:66]\n",
    "    x_pred = y_pred[:,1:66]\n",
    "    \n",
    "    # Normalize each vector\n",
    "    comp_true = tf.conj(x_true)\n",
    "    norm_true = x_true / tf.sqrt(tf.reduce_sum(tf.multiply(x_true,comp_true)))\n",
    "    \n",
    "    comp_pred = tf.conj(x_pred)\n",
    "    norm_pred = x_pred / tf.sqrt(tf.reduce_sum(tf.multiply(x_pred,comp_pred)))\n",
    "    \n",
    "    comp_p2 = tf.conj(norm_pred)\n",
    "    acc = tf.real(tf.reduce_sum(tf.multiply(norm_true,comp_p2)))\n",
    "    acc = -1.0 * acc * acc\n",
    "    \n",
    "    loss_mse = K.mean(K.square(y_pred-y_true))\n",
    "    \n",
    "    return acc + loss_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all(input_path,output_path,test_input_path,test_output_path):\n",
    "    \n",
    "    input = loadmat(input_path)\n",
    "    output = loadmat(output_path)\n",
    "    \n",
    "    #X = np.array(input['train_input_shore'])\n",
    "    X = np.array(input['train_shore_input'])\n",
    "    y = np.array(output['train_shore_output'])\n",
    "    \n",
    "    # Get dimensions of arrays\n",
    "    print('Training Data Information \\n')\n",
    "    x_size = X.shape\n",
    "    print('Input Array Shape',x_size)\n",
    "    y_size = y.shape\n",
    "    print ('Output Array Shape',y_size)\n",
    "    \n",
    "    test_input = loadmat(test_input_path)\n",
    "    test_output = loadmat(test_output_path)\n",
    "    \n",
    "    #X_test = np.array(test_input['test_input_shore'])\n",
    "    X_test = np.array(test_input['test_shore_input'])\n",
    "    y_test = np.array(test_output['test_shore_output'])\n",
    "    \n",
    "    # Get dimensions of Test data\n",
    "    print('Testing Data information \\n')\n",
    "    x_size = X_test.shape\n",
    "    print('Test Input Shape',x_size)\n",
    "    y_size = y_test.shape\n",
    "    print('Test Output Shape',y_size)\n",
    "    \n",
    "    return X,y,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_nn2():\n",
    "    model = Sequential()\n",
    "    # Input layer with dimension 1 and hidden layer i with 128 neurons.\n",
    "    model.add(Dense(50, input_shape=(50,)))\n",
    "    model.add(Dense(400))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.6))\n",
    "    # Hidden layer j with 64 neurons plus activation layer.\n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.5))\n",
    "    # Hidden layer k with 64 neurons.\n",
    "    model.add(Dense(66))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(400))\n",
    "    #model.add(Activation(\"relu\"))\n",
    "    # Output Layer.\n",
    "    model.add(Dense(50))\n",
    " \n",
    "    # Model is derived and compiled using mean square error as loss\n",
    "    # function, accuracy as metric and gradient descent optimizer.\n",
    "    model.compile(loss='mse', optimizer='nadam', metrics=['mse','mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Originally number of epochs was set to 1000, currently at 10.\n",
    "def train_nn(model, X, y, out_dir, val_size=0.1, n_epoch=1000):\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    csv_logger = CSVLogger(os.path.join(out_dir, 'results.csv'))\n",
    "\n",
    "    model.fit(X, y, epochs=n_epoch, batch_size=10000, verbose=1, shuffle=True, validation_split=val_size, callbacks=[csv_logger])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_estimate(model, X, y, out_file, indices):\n",
    "    #y_pred = model.predict(X)\n",
    "\n",
    "    #y_pred = y_scaler.inverse_transform(y_pred)\n",
    "    #y = y_scaler.inverse_transform(y)\n",
    "\n",
    "    out_path = os.path.dirname(out_file)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "     \n",
    "    y_pred = model.predict(X)\n",
    "    savemat(out_file, mdict={'out_pred': y_pred, 'out_true': y, 'indices': indices})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_test_set_prediction(model, out_file, X_test, y_test):\n",
    "    \n",
    "    # Get dimensions of arrays\n",
    "    x_size = X_test.shape\n",
    "    print('Hist 72: Input Array Shape',x_size)\n",
    "    y_size = y_test.shape\n",
    "    print ('Output Hist 72: Array Shape',y_size)\n",
    "    \n",
    "    # Make Predictions\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    # If output path does not exist, create it\n",
    "    out_path = os.path.dirname(out_file)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    \n",
    "    savemat(out_file, mdict={'out_pred': pred, 'out_true': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_vishabyte_predictions(model, out_file):\n",
    "    input_file_path = r'D:\\Users\\Vishwesh\\PycharmProjects\\shore_mapmri\\Data\\log_vish_feed_v3.mat'\n",
    "    input_file_path = os.path.normpath(input_file_path)\n",
    "    input_test = loadmat(input_file_path)\n",
    "    X_f_t = np.array(input_test['log_vish_feed'])\n",
    "    # Get dimensions of arrays\n",
    "    x_size = X_f_t.shape\n",
    "    print('Vishabyte: Input Array Shape',x_size)\n",
    "    pred = model.predict(X_f_t)\n",
    "    \n",
    "    # If output path does not exist, create it\n",
    "    out_path = os.path.dirname(out_file)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "        \n",
    "    # In vivo save matrix\n",
    "    savemat(out_file, mdict={'out_pred': pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    #args = parse_args()\n",
    "    work_dir = r'D:\\Users\\Vishwesh\\PycharmProjects\\shore_mapmri\\dl_results'\n",
    "    word_dir = os.path.normpath(work_dir)\n",
    "    \n",
    "    exp = 'Non_Neg_Shore_input_Shore_decayed_output_v4'\n",
    "    itr = 20 # Estimated from CV\n",
    "\n",
    "    train_input_data_path = r'D:\\Users\\Vishwesh\\PycharmProjects\\shore_mapmri\\Data\\log_train_input_shore_v5.mat'\n",
    "    train_output_data_path = r'D:\\Users\\Vishwesh\\PycharmProjects\\shore_mapmri\\Data\\log_train_decayed_output_shore_v5.mat'\n",
    "    train_input_data_path = os.path.normpath(train_input_data_path)\n",
    "    train_output_data_path = os.path.normpath(train_output_data_path)\n",
    "    \n",
    "    test_input_data_path = r'D:\\Users\\Vishwesh\\PycharmProjects\\shore_mapmri\\Data\\log_test_input_shore_v5.mat'\n",
    "    test_output_data_path = r'D:\\Users\\Vishwesh\\PycharmProjects\\shore_mapmri\\Data\\log_test_decayed_output_shore_v5.mat'\n",
    "    test_input_data_path = os.path.normpath(test_input_data_path)\n",
    "    test_output_data_path = os.path.normpath(test_output_data_path)\n",
    "    \n",
    "    print (\"Loading data\")\n",
    "    X, y, X_b_test, y_b_test = load_all(train_input_data_path,train_output_data_path,test_input_data_path,test_output_data_path)\n",
    "    indices = np.array(range(X.shape[0]))+1\n",
    "\n",
    "    out_start_dir = os.path.join(work_dir,exp)\n",
    "    if not os.path.exists(out_start_dir):\n",
    "        os.makedirs(out_start_dir)\n",
    "\n",
    "    seed1 = 46\n",
    "    seed2 = 23\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=seed1,shuffle=True,)\n",
    "    \n",
    "    fold_num = 0\n",
    "    model_D = build_nn2()\n",
    "    \n",
    "    \n",
    "    for train, test in kf.split(X):\n",
    "        # Set up training / testing data\n",
    "        fold_num += 1\n",
    "        X_train = X[train,:]\n",
    "        y_train = y[train,:]\n",
    "        X_test = X[test,:]\n",
    "        y_test = y[test,:]\n",
    "        indices_train = indices[train]\n",
    "        indices_test = indices[test]\n",
    "        #X_train, X_test, y_train, y_test, X_scaler, y_scaler = norm_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "        # Want to submit this w/ 1000 different initializations\n",
    "        np.random.seed(seed=seed2)\n",
    "\n",
    "        # Deep NN\n",
    "        print (\"Training DNN with %d iterations, fold %d\" % (itr, fold_num))\n",
    "        out_dir_DNN = os.path.join(out_start_dir, str(fold_num))\n",
    "        model_D = train_nn(model_D, X_train, y_train, out_dir_DNN, n_epoch=itr, val_size=0.1)\n",
    "\n",
    "        print (\"Saving training outputs\")\n",
    "        end_dir = os.path.join(out_start_dir, str(fold_num), 'training.csv')\n",
    "        save_estimate(model_D, X_train, y_train, end_dir,indices_train)\n",
    "\n",
    "        print (\"Saving testing outputs\")\n",
    "        end_dir = os.path.join(out_start_dir, str(fold_num), 'testing.csv')\n",
    "        save_estimate(model_D, X_test, y_test, end_dir,indices_test)\n",
    "\n",
    "    #print (\"Saving Vishabyte outputs\")\n",
    "    #end_dir = os.path.join(out_start_dir, str('Vishabyte_Test'), 'result_vol_invivo_vish_b2000.mat')\n",
    "    #save_vishabyte_predictions(model_D, end_dir)\n",
    "\n",
    "    print (\"Saving Histology blind test outputs\")\n",
    "    end_dir = os.path.join(out_start_dir, str('Hist_Blind_72_Test'), 'result.mat')\n",
    "    save_test_set_prediction(model_D, end_dir, X_b_test, y_b_test)\n",
    "    \n",
    "    print (\"Saving Vishabyte Predictions\")\n",
    "    end_dir = os.path.join(out_start_dir, str('Vishabyte_Preds'), 'result.mat')\n",
    "    save_vishabyte_predictions(model_D, end_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Training Data Information \n",
      "\n",
      "Input Array Shape (49995, 50)\n",
      "Output Array Shape (49995, 50)\n",
      "Testing Data information \n",
      "\n",
      "Test Input Shape (7272, 50)\n",
      "Test Output Shape (7272, 50)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 400)               20400     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 66)                13266     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 66)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 200)               13400     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 50)                20050     \n",
      "=================================================================\n",
      "Total params: 230,266\n",
      "Trainable params: 230,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training DNN with 20 iterations, fold 1\n",
      "Train on 35996 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "35996/35996 [==============================] - 0s - loss: 77393131.9298 - mean_squared_error: 77393140.1534 - mean_absolute_error: 3685.9946 - val_loss: 14737957.0000 - val_mean_squared_error: 14737958.0000 - val_mean_absolute_error: 2292.2349\n",
      "Epoch 2/20\n",
      "35996/35996 [==============================] - 0s - loss: 30140074.4483 - mean_squared_error: 30140076.4494 - mean_absolute_error: 3135.9206 - val_loss: 12900937.0000 - val_mean_squared_error: 12900938.0000 - val_mean_absolute_error: 1960.0651\n",
      "Epoch 3/20\n",
      "35996/35996 [==============================] - 0s - loss: 27070481.0454 - mean_squared_error: 27070481.3797 - mean_absolute_error: 2699.3667 - val_loss: 11897802.0000 - val_mean_squared_error: 11897804.0000 - val_mean_absolute_error: 1880.7179\n",
      "Epoch 4/20\n",
      "35996/35996 [==============================] - 0s - loss: 26302144.2649 - mean_squared_error: 26302145.1548 - mean_absolute_error: 2645.9120 - val_loss: 11637188.0000 - val_mean_squared_error: 11637189.0000 - val_mean_absolute_error: 1875.8269\n",
      "Epoch 5/20\n",
      "35996/35996 [==============================] - 0s - loss: 26563141.4130 - mean_squared_error: 26563144.3029 - mean_absolute_error: 2655.5815 - val_loss: 11862806.0000 - val_mean_squared_error: 11862806.0000 - val_mean_absolute_error: 1882.3550\n",
      "Epoch 6/20\n",
      "35996/35996 [==============================] - 0s - loss: 25446288.5012 - mean_squared_error: 25446290.5023 - mean_absolute_error: 2632.6176 - val_loss: 11555826.0000 - val_mean_squared_error: 11555828.0000 - val_mean_absolute_error: 1897.6384\n",
      "Epoch 7/20\n",
      "35996/35996 [==============================] - 0s - loss: 25586500.7674 - mean_squared_error: 25586501.9904 - mean_absolute_error: 2641.7968 - val_loss: 11781728.0000 - val_mean_squared_error: 11781730.0000 - val_mean_absolute_error: 1911.1779\n",
      "Epoch 8/20\n",
      "35996/35996 [==============================] - 0s - loss: 25287036.4145 - mean_squared_error: 25287037.4150 - mean_absolute_error: 2635.6770 - val_loss: 12045718.0000 - val_mean_squared_error: 12045719.0000 - val_mean_absolute_error: 1914.3872\n",
      "Epoch 9/20\n",
      "35996/35996 [==============================] - 0s - loss: 24945369.3210 - mean_squared_error: 24945370.7665 - mean_absolute_error: 2629.8474 - val_loss: 11663872.0000 - val_mean_squared_error: 11663873.0000 - val_mean_absolute_error: 1905.4388\n",
      "Epoch 10/20\n",
      "35996/35996 [==============================] - 0s - loss: 25059589.6144 - mean_squared_error: 25059590.8374 - mean_absolute_error: 2637.5987 - val_loss: 11874626.0000 - val_mean_squared_error: 11874627.0000 - val_mean_absolute_error: 1907.0995\n",
      "Epoch 11/20\n",
      "35996/35996 [==============================] - 0s - loss: 23769033.2155 - mean_squared_error: 23769034.6610 - mean_absolute_error: 2593.9525 - val_loss: 11500860.0000 - val_mean_squared_error: 11500861.0000 - val_mean_absolute_error: 1855.6476\n",
      "Epoch 12/20\n",
      "35996/35996 [==============================] - 0s - loss: 23751708.6670 - mean_squared_error: 23751712.4456 - mean_absolute_error: 2551.3125 - val_loss: 11539024.0000 - val_mean_squared_error: 11539026.0000 - val_mean_absolute_error: 1834.2924\n",
      "Epoch 13/20\n",
      "35996/35996 [==============================] - 0s - loss: 22586405.9109 - mean_squared_error: 22586407.1339 - mean_absolute_error: 2515.5850 - val_loss: 11207431.0000 - val_mean_squared_error: 11207432.0000 - val_mean_absolute_error: 1825.5100\n",
      "Epoch 14/20\n",
      "35996/35996 [==============================] - 0s - loss: 21699062.4045 - mean_squared_error: 21699063.0719 - mean_absolute_error: 2487.9881 - val_loss: 11153736.0000 - val_mean_squared_error: 11153738.0000 - val_mean_absolute_error: 1820.6106\n",
      "Epoch 15/20\n",
      "35996/35996 [==============================] - 0s - loss: 20918853.3166 - mean_squared_error: 20918853.7615 - mean_absolute_error: 2458.4255 - val_loss: 11301190.0000 - val_mean_squared_error: 11301190.0000 - val_mean_absolute_error: 1825.3643\n",
      "Epoch 16/20\n",
      "35996/35996 [==============================] - 0s - loss: 20938170.4934 - mean_squared_error: 20938172.0496 - mean_absolute_error: 2515.9796 - val_loss: 12194419.0000 - val_mean_squared_error: 12194420.0000 - val_mean_absolute_error: 2014.2048\n",
      "Epoch 17/20\n",
      "35996/35996 [==============================] - 0s - loss: 19005895.0317 - mean_squared_error: 19005897.3659 - mean_absolute_error: 2495.5640 - val_loss: 11192247.0000 - val_mean_squared_error: 11192248.0000 - val_mean_absolute_error: 1882.2559\n",
      "Epoch 18/20\n",
      "35996/35996 [==============================] - 0s - loss: 20925849.4053 - mean_squared_error: 20925852.4058 - mean_absolute_error: 2466.3321 - val_loss: 10980102.0000 - val_mean_squared_error: 10980103.0000 - val_mean_absolute_error: 1758.6824\n",
      "Epoch 19/20\n",
      "35996/35996 [==============================] - 0s - loss: 18888075.4504 - mean_squared_error: 18888075.8953 - mean_absolute_error: 2342.1193 - val_loss: 11005480.0000 - val_mean_squared_error: 11005480.0000 - val_mean_absolute_error: 1786.1123\n",
      "Epoch 20/20\n",
      "35996/35996 [==============================] - 0s - loss: 18544638.3234 - mean_squared_error: 18544639.6571 - mean_absolute_error: 2369.6743 - val_loss: 11116368.0000 - val_mean_squared_error: 11116368.0000 - val_mean_absolute_error: 1833.3760\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Training DNN with 20 iterations, fold 2\n",
      "Train on 35996 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "35996/35996 [==============================] - 0s - loss: 18072622.2485 - mean_squared_error: 18072622.6934 - mean_absolute_error: 2381.5194 - val_loss: 11444330.0000 - val_mean_squared_error: 11444330.0000 - val_mean_absolute_error: 1878.3082\n",
      "Epoch 2/20\n",
      "35996/35996 [==============================] - 0s - loss: 18069717.6640 - mean_squared_error: 18069716.1089 - mean_absolute_error: 2417.9346 - val_loss: 11370949.0000 - val_mean_squared_error: 11370952.0000 - val_mean_absolute_error: 1812.4148\n",
      "Epoch 3/20\n",
      "35996/35996 [==============================] - 0s - loss: 18982255.6144 - mean_squared_error: 18982257.1706 - mean_absolute_error: 2363.3568 - val_loss: 10602551.0000 - val_mean_squared_error: 10602552.0000 - val_mean_absolute_error: 1705.6797\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35996/35996 [==============================] - 0s - loss: 16961066.7279 - mean_squared_error: 16961067.7284 - mean_absolute_error: 2227.5329 - val_loss: 10235868.0000 - val_mean_squared_error: 10235869.0000 - val_mean_absolute_error: 1665.5360\n",
      "Epoch 5/20\n",
      "35996/35996 [==============================] - 0s - loss: 17350073.8079 - mean_squared_error: 17350074.4194 - mean_absolute_error: 2245.7145 - val_loss: 10379023.0000 - val_mean_squared_error: 10379024.0000 - val_mean_absolute_error: 1717.0264\n",
      "Epoch 6/20\n",
      "35996/35996 [==============================] - 0s - loss: 15904219.6403 - mean_squared_error: 15904220.2518 - mean_absolute_error: 2214.4123 - val_loss: 10710292.0000 - val_mean_squared_error: 10710293.0000 - val_mean_absolute_error: 1735.7784\n",
      "Epoch 7/20\n",
      "35996/35996 [==============================] - 0s - loss: 14998342.7850 - mean_squared_error: 14998344.1187 - mean_absolute_error: 2163.1293 - val_loss: 10627659.0000 - val_mean_squared_error: 10627660.0000 - val_mean_absolute_error: 1773.2336\n",
      "Epoch 8/20\n",
      "35996/35996 [==============================] - 0s - loss: 16950135.4587 - mean_squared_error: 16950137.5705 - mean_absolute_error: 2306.1176 - val_loss: 10461247.0000 - val_mean_squared_error: 10461248.0000 - val_mean_absolute_error: 1660.4797\n",
      "Epoch 9/20\n",
      "35996/35996 [==============================] - 0s - loss: 15198744.6814 - mean_squared_error: 15198746.0151 - mean_absolute_error: 2134.4129 - val_loss: 10794054.0000 - val_mean_squared_error: 10794055.0000 - val_mean_absolute_error: 1719.7644\n",
      "Epoch 10/20\n",
      "35996/35996 [==============================] - 0s - loss: 15869479.5196 - mean_squared_error: 15869479.9646 - mean_absolute_error: 2149.0993 - val_loss: 9723442.0000 - val_mean_squared_error: 9723444.0000 - val_mean_absolute_error: 1605.4092\n",
      "Epoch 11/20\n",
      "35996/35996 [==============================] - 0s - loss: 14927703.7939 - mean_squared_error: 14927704.6832 - mean_absolute_error: 2080.4440 - val_loss: 9452602.0000 - val_mean_squared_error: 9452604.0000 - val_mean_absolute_error: 1561.8160\n",
      "Epoch 12/20\n",
      "35996/35996 [==============================] - 0s - loss: 14041046.0122 - mean_squared_error: 14041046.6237 - mean_absolute_error: 2018.2657 - val_loss: 9032178.0000 - val_mean_squared_error: 9032178.0000 - val_mean_absolute_error: 1523.6080\n",
      "Epoch 13/20\n",
      "35996/35996 [==============================] - 0s - loss: 15049745.9531 - mean_squared_error: 15049747.2315 - mean_absolute_error: 2054.9389 - val_loss: 9467382.0000 - val_mean_squared_error: 9467382.0000 - val_mean_absolute_error: 1556.3462\n",
      "Epoch 14/20\n",
      "35996/35996 [==============================] - 0s - loss: 15455171.5093 - mean_squared_error: 15455172.2320 - mean_absolute_error: 2098.6761 - val_loss: 10421592.0000 - val_mean_squared_error: 10421594.0000 - val_mean_absolute_error: 1669.5757\n",
      "Epoch 15/20\n",
      "35996/35996 [==============================] - 0s - loss: 13691011.4370 - mean_squared_error: 13691013.0486 - mean_absolute_error: 2051.1585 - val_loss: 11033687.0000 - val_mean_squared_error: 11033688.0000 - val_mean_absolute_error: 1655.7134\n",
      "Epoch 16/20\n",
      "35996/35996 [==============================] - 0s - loss: 12675485.4966 - mean_squared_error: 12675486.8303 - mean_absolute_error: 1971.2167 - val_loss: 11363371.0000 - val_mean_squared_error: 11363372.0000 - val_mean_absolute_error: 1670.4990\n",
      "Epoch 17/20\n",
      "35996/35996 [==============================] - 0s - loss: 12748787.4057 - mean_squared_error: 12748788.0172 - mean_absolute_error: 1975.5807 - val_loss: 12941269.0000 - val_mean_squared_error: 12941271.0000 - val_mean_absolute_error: 1738.6426\n",
      "Epoch 18/20\n",
      "35996/35996 [==============================] - 0s - loss: 13508699.5677 - mean_squared_error: 13508700.7349 - mean_absolute_error: 1999.4997 - val_loss: 14239676.0000 - val_mean_squared_error: 14239677.0000 - val_mean_absolute_error: 1780.6588\n",
      "Epoch 19/20\n",
      "35996/35996 [==============================] - 0s - loss: 13858245.1661 - mean_squared_error: 13858246.0555 - mean_absolute_error: 1998.7518 - val_loss: 15069010.0000 - val_mean_squared_error: 15069011.0000 - val_mean_absolute_error: 1808.1750\n",
      "Epoch 20/20\n",
      "35996/35996 [==============================] - 0s - loss: 14176036.6606 - mean_squared_error: 14176037.5499 - mean_absolute_error: 2000.7673 - val_loss: 13875142.0000 - val_mean_squared_error: 13875143.0000 - val_mean_absolute_error: 1749.9615\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Training DNN with 20 iterations, fold 3\n",
      "Train on 35996 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "35996/35996 [==============================] - 0s - loss: 13145984.5738 - mean_squared_error: 13145985.9075 - mean_absolute_error: 1947.5163 - val_loss: 13324505.0000 - val_mean_squared_error: 13324506.0000 - val_mean_absolute_error: 1731.7346\n",
      "Epoch 2/20\n",
      "35996/35996 [==============================] - 0s - loss: 13113824.0698 - mean_squared_error: 13113824.2369 - mean_absolute_error: 1948.3663 - val_loss: 12960424.0000 - val_mean_squared_error: 12960426.0000 - val_mean_absolute_error: 1720.2137\n",
      "Epoch 3/20\n",
      "35996/35996 [==============================] - 0s - loss: 12967678.6864 - mean_squared_error: 12967679.2426 - mean_absolute_error: 1955.4035 - val_loss: 12986728.0000 - val_mean_squared_error: 12986729.0000 - val_mean_absolute_error: 1737.8130\n",
      "Epoch 4/20\n",
      "35996/35996 [==============================] - 0s - loss: 12844186.9861 - mean_squared_error: 12844187.5976 - mean_absolute_error: 1965.5261 - val_loss: 12442782.0000 - val_mean_squared_error: 12442784.0000 - val_mean_absolute_error: 1720.1798\n",
      "Epoch 5/20\n",
      "35996/35996 [==============================] - 0s - loss: 12566408.4941 - mean_squared_error: 12566408.9943 - mean_absolute_error: 1952.1899 - val_loss: 12657982.0000 - val_mean_squared_error: 12657984.0000 - val_mean_absolute_error: 1728.1301\n",
      "Epoch 6/20\n",
      "35996/35996 [==============================] - 0s - loss: 13169929.6151 - mean_squared_error: 13169930.1153 - mean_absolute_error: 1986.5599 - val_loss: 12484596.0000 - val_mean_squared_error: 12484597.0000 - val_mean_absolute_error: 1726.5636\n",
      "Epoch 7/20\n",
      "35996/35996 [==============================] - 0s - loss: 12804976.6922 - mean_squared_error: 12804977.8593 - mean_absolute_error: 1966.2966 - val_loss: 12827469.0000 - val_mean_squared_error: 12827470.0000 - val_mean_absolute_error: 1747.9358\n",
      "Epoch 8/20\n",
      "35996/35996 [==============================] - 0s - loss: 13059670.1440 - mean_squared_error: 13059670.3111 - mean_absolute_error: 1986.0730 - val_loss: 13299937.0000 - val_mean_squared_error: 13299939.0000 - val_mean_absolute_error: 1745.7587\n",
      "Epoch 9/20\n",
      "35996/35996 [==============================] - 0s - loss: 13092185.9047 - mean_squared_error: 13092186.3496 - mean_absolute_error: 1951.8461 - val_loss: 12954639.0000 - val_mean_squared_error: 12954640.0000 - val_mean_absolute_error: 1704.8030\n",
      "Epoch 10/20\n",
      "35996/35996 [==============================] - 0s - loss: 12829352.8193 - mean_squared_error: 12829353.9864 - mean_absolute_error: 1918.0082 - val_loss: 12610892.0000 - val_mean_squared_error: 12610893.0000 - val_mean_absolute_error: 1698.2982\n",
      "Epoch 11/20\n",
      "35996/35996 [==============================] - 0s - loss: 12708801.9217 - mean_squared_error: 12708802.4219 - mean_absolute_error: 1923.1784 - val_loss: 12513289.0000 - val_mean_squared_error: 12513290.0000 - val_mean_absolute_error: 1694.4617\n",
      "Epoch 12/20\n",
      "35996/35996 [==============================] - 0s - loss: 12218754.1002 - mean_squared_error: 12218754.6005 - mean_absolute_error: 1893.8466 - val_loss: 11921776.0000 - val_mean_squared_error: 11921777.0000 - val_mean_absolute_error: 1664.8093\n",
      "Epoch 13/20\n",
      "35996/35996 [==============================] - 0s - loss: 12191146.3420 - mean_squared_error: 12191146.3426 - mean_absolute_error: 1901.7142 - val_loss: 12267969.0000 - val_mean_squared_error: 12267970.0000 - val_mean_absolute_error: 1697.6344\n",
      "Epoch 14/20\n",
      "35996/35996 [==============================] - 0s - loss: 12463398.3620 - mean_squared_error: 12463399.5292 - mean_absolute_error: 1918.3402 - val_loss: 12057488.0000 - val_mean_squared_error: 12057490.0000 - val_mean_absolute_error: 1665.5358\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35996/35996 [==============================] - 0s - loss: 12286463.9934 - mean_squared_error: 12286465.3271 - mean_absolute_error: 1891.8015 - val_loss: 12501164.0000 - val_mean_squared_error: 12501166.0000 - val_mean_absolute_error: 1685.9946\n",
      "Epoch 16/20\n",
      "35996/35996 [==============================] - 0s - loss: 12539529.4028 - mean_squared_error: 12539529.6812 - mean_absolute_error: 1899.3986 - val_loss: 12374231.0000 - val_mean_squared_error: 12374233.0000 - val_mean_absolute_error: 1669.1255\n",
      "Epoch 17/20\n",
      "35996/35996 [==============================] - 0s - loss: 12515767.8432 - mean_squared_error: 12515768.5660 - mean_absolute_error: 1890.3424 - val_loss: 12708633.0000 - val_mean_squared_error: 12708633.0000 - val_mean_absolute_error: 1696.3859\n",
      "Epoch 18/20\n",
      "35996/35996 [==============================] - 0s - loss: 12651030.0326 - mean_squared_error: 12651031.0885 - mean_absolute_error: 1910.8975 - val_loss: 11588904.0000 - val_mean_squared_error: 11588906.0000 - val_mean_absolute_error: 1641.4114\n",
      "Epoch 19/20\n",
      "35996/35996 [==============================] - 0s - loss: 11472773.5804 - mean_squared_error: 11472773.7475 - mean_absolute_error: 1845.0683 - val_loss: 11978342.0000 - val_mean_squared_error: 11978343.0000 - val_mean_absolute_error: 1658.4772\n",
      "Epoch 20/20\n",
      "35996/35996 [==============================] - 0s - loss: 11881650.2120 - mean_squared_error: 11881650.2679 - mean_absolute_error: 1863.9759 - val_loss: 11621379.0000 - val_mean_squared_error: 11621380.0000 - val_mean_absolute_error: 1633.34395\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Training DNN with 20 iterations, fold 4\n",
      "Train on 35996 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "35996/35996 [==============================] - 0s - loss: 11661824.2951 - mean_squared_error: 11661825.2957 - mean_absolute_error: 1850.4290 - val_loss: 11851679.0000 - val_mean_squared_error: 11851681.0000 - val_mean_absolute_error: 1652.7019\n",
      "Epoch 2/20\n",
      "35996/35996 [==============================] - 0s - loss: 11858868.8056 - mean_squared_error: 11858868.9728 - mean_absolute_error: 1858.1781 - val_loss: 11674038.0000 - val_mean_squared_error: 11674039.0000 - val_mean_absolute_error: 1632.4866\n",
      "Epoch 3/20\n",
      "35996/35996 [==============================] - 0s - loss: 11741716.3060 - mean_squared_error: 11741717.9175 - mean_absolute_error: 1851.6620 - val_loss: 11884041.0000 - val_mean_squared_error: 11884042.0000 - val_mean_absolute_error: 1658.6704\n",
      "Epoch 4/20\n",
      "35996/35996 [==============================] - 0s - loss: 12047921.7325 - mean_squared_error: 12047922.6218 - mean_absolute_error: 1881.3902 - val_loss: 11413458.0000 - val_mean_squared_error: 11413461.0000 - val_mean_absolute_error: 1629.5121\n",
      "Epoch 5/20\n",
      "35996/35996 [==============================] - 0s - loss: 11504826.4672 - mean_squared_error: 11504826.2452 - mean_absolute_error: 1842.9600 - val_loss: 11569892.0000 - val_mean_squared_error: 11569894.0000 - val_mean_absolute_error: 1624.4535\n",
      "Epoch 6/20\n",
      "35996/35996 [==============================] - 0s - loss: 11437458.1030 - mean_squared_error: 11437458.7699 - mean_absolute_error: 1831.1860 - val_loss: 11478388.0000 - val_mean_squared_error: 11478388.0000 - val_mean_absolute_error: 1619.3622\n",
      "Epoch 7/20\n",
      "35996/35996 [==============================] - 0s - loss: 11487311.8623 - mean_squared_error: 11487313.0294 - mean_absolute_error: 1827.2757 - val_loss: 12105690.0000 - val_mean_squared_error: 12105690.0000 - val_mean_absolute_error: 1648.2396\n",
      "Epoch 8/20\n",
      "35996/35996 [==============================] - 0s - loss: 12199378.2535 - mean_squared_error: 12199378.8650 - mean_absolute_error: 1861.7811 - val_loss: 12065475.0000 - val_mean_squared_error: 12065476.0000 - val_mean_absolute_error: 1643.2297\n",
      "Epoch 9/20\n",
      "35996/35996 [==============================] - 0s - loss: 11529482.2720 - mean_squared_error: 11529482.7170 - mean_absolute_error: 1819.0267 - val_loss: 11011486.0000 - val_mean_squared_error: 11011488.0000 - val_mean_absolute_error: 1584.0459\n",
      "Epoch 10/20\n",
      "35996/35996 [==============================] - 0s - loss: 10845714.4527 - mean_squared_error: 10845714.6198 - mean_absolute_error: 1779.9091 - val_loss: 10626514.0000 - val_mean_squared_error: 10626516.0000 - val_mean_absolute_error: 1572.8903\n",
      "Epoch 11/20\n",
      "35996/35996 [==============================] - 0s - loss: 10820474.1749 - mean_squared_error: 10820474.6752 - mean_absolute_error: 1792.0080 - val_loss: 10869646.0000 - val_mean_squared_error: 10869649.0000 - val_mean_absolute_error: 1595.0535\n",
      "Epoch 12/20\n",
      "35996/35996 [==============================] - 0s - loss: 10971666.6887 - mean_squared_error: 10971667.9112 - mean_absolute_error: 1809.5158 - val_loss: 10590050.0000 - val_mean_squared_error: 10590052.0000 - val_mean_absolute_error: 1590.6637\n",
      "Epoch 13/20\n",
      "35996/35996 [==============================] - 0s - loss: 10977996.4143 - mean_squared_error: 10977996.7480 - mean_absolute_error: 1820.7890 - val_loss: 10228281.0000 - val_mean_squared_error: 10228282.0000 - val_mean_absolute_error: 1556.5887\n",
      "Epoch 14/20\n",
      "35996/35996 [==============================] - 0s - loss: 10784855.8984 - mean_squared_error: 10784856.6212 - mean_absolute_error: 1795.7754 - val_loss: 11034965.0000 - val_mean_squared_error: 11034968.0000 - val_mean_absolute_error: 1613.4786\n",
      "Epoch 15/20\n",
      "35996/35996 [==============================] - 0s - loss: 11184216.2613 - mean_squared_error: 11184216.8728 - mean_absolute_error: 1816.3306 - val_loss: 10854023.0000 - val_mean_squared_error: 10854025.0000 - val_mean_absolute_error: 1576.3398\n",
      "Epoch 16/20\n",
      "35996/35996 [==============================] - 0s - loss: 11045038.8491 - mean_squared_error: 11045039.9050 - mean_absolute_error: 1789.0256 - val_loss: 10889115.0000 - val_mean_squared_error: 10889116.0000 - val_mean_absolute_error: 1578.1816\n",
      "Epoch 17/20\n",
      "35996/35996 [==============================] - 0s - loss: 11408553.6047 - mean_squared_error: 11408554.0497 - mean_absolute_error: 1809.9386 - val_loss: 10450469.0000 - val_mean_squared_error: 10450470.0000 - val_mean_absolute_error: 1548.4922\n",
      "Epoch 18/20\n",
      "35996/35996 [==============================] - 0s - loss: 10764024.7531 - mean_squared_error: 10764025.4199 - mean_absolute_error: 1764.7915 - val_loss: 10180607.0000 - val_mean_squared_error: 10180609.0000 - val_mean_absolute_error: 1532.8901\n",
      "Epoch 19/20\n",
      "35996/35996 [==============================] - 0s - loss: 10545329.0813 - mean_squared_error: 10545329.5816 - mean_absolute_error: 1755.8103 - val_loss: 10527327.0000 - val_mean_squared_error: 10527328.0000 - val_mean_absolute_error: 1558.2345\n",
      "Epoch 20/20\n",
      "35996/35996 [==============================] - 0s - loss: 10848041.5857 - mean_squared_error: 10848041.9194 - mean_absolute_error: 1777.2867 - val_loss: 10326803.0000 - val_mean_squared_error: 10326806.0000 - val_mean_absolute_error: 1553.5156\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Training DNN with 20 iterations, fold 5\n",
      "Train on 35996 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "35996/35996 [==============================] - 0s - loss: 10615085.4727 - mean_squared_error: 10615085.6952 - mean_absolute_error: 1780.7529 - val_loss: 9761210.0000 - val_mean_squared_error: 9761211.0000 - val_mean_absolute_error: 1535.0187\n",
      "Epoch 2/20\n",
      "35996/35996 [==============================] - 0s - loss: 10029166.6346 - mean_squared_error: 10029166.5239 - mean_absolute_error: 1737.7985 - val_loss: 9530630.0000 - val_mean_squared_error: 9530631.0000 - val_mean_absolute_error: 1511.5063\n",
      "Epoch 3/20\n",
      "35996/35996 [==============================] - 0s - loss: 10016996.8443 - mean_squared_error: 10016997.6224 - mean_absolute_error: 1733.5518 - val_loss: 9969181.0000 - val_mean_squared_error: 9969182.0000 - val_mean_absolute_error: 1539.2773\n",
      "Epoch 4/20\n",
      "35996/35996 [==============================] - 0s - loss: 10310074.5343 - mean_squared_error: 10310075.3124 - mean_absolute_error: 1750.8298 - val_loss: 9695568.0000 - val_mean_squared_error: 9695569.0000 - val_mean_absolute_error: 1514.6958\n",
      "Epoch 5/20\n",
      "35996/35996 [==============================] - 0s - loss: 10185717.3503 - mean_squared_error: 10185717.9618 - mean_absolute_error: 1738.9773 - val_loss: 9797640.0000 - val_mean_squared_error: 9797640.0000 - val_mean_absolute_error: 1516.9596\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35996/35996 [==============================] - 0s - loss: 10406047.1479 - mean_squared_error: 10406047.3704 - mean_absolute_error: 1750.6974 - val_loss: 10193221.0000 - val_mean_squared_error: 10193221.0000 - val_mean_absolute_error: 1556.5679\n",
      "Epoch 7/20\n",
      "35996/35996 [==============================] - 0s - loss: 10608130.2658 - mean_squared_error: 10608130.8773 - mean_absolute_error: 1772.0069 - val_loss: 10010754.0000 - val_mean_squared_error: 10010756.0000 - val_mean_absolute_error: 1534.7163\n",
      "Epoch 8/20\n",
      "35996/35996 [==============================] - 0s - loss: 10270088.5344 - mean_squared_error: 10270089.0347 - mean_absolute_error: 1743.2407 - val_loss: 9559535.0000 - val_mean_squared_error: 9559535.0000 - val_mean_absolute_error: 1498.7858\n",
      "Epoch 9/20\n",
      "35996/35996 [==============================] - 0s - loss: 9953170.2142 - mean_squared_error: 9953171.2148 - mean_absolute_error: 1713.0647 - val_loss: 9572194.0000 - val_mean_squared_error: 9572195.0000 - val_mean_absolute_error: 1498.6681\n",
      "Epoch 10/20\n",
      "35996/35996 [==============================] - 0s - loss: 10040662.6276 - mean_squared_error: 10040663.5169 - mean_absolute_error: 1718.1747 - val_loss: 9313354.0000 - val_mean_squared_error: 9313356.0000 - val_mean_absolute_error: 1482.7572\n",
      "Epoch 11/20\n",
      "35996/35996 [==============================] - 0s - loss: 9886563.3068 - mean_squared_error: 9886563.6405 - mean_absolute_error: 1709.6183 - val_loss: 9858530.0000 - val_mean_squared_error: 9858531.0000 - val_mean_absolute_error: 1514.5685\n",
      "Epoch 12/20\n",
      "35996/35996 [==============================] - 0s - loss: 10200476.9095 - mean_squared_error: 10200476.9654 - mean_absolute_error: 1730.2663 - val_loss: 9309857.0000 - val_mean_squared_error: 9309858.0000 - val_mean_absolute_error: 1502.3918\n",
      "Epoch 13/20\n",
      "35996/35996 [==============================] - 0s - loss: 9839115.7202 - mean_squared_error: 9839115.9427 - mean_absolute_error: 1724.5185 - val_loss: 8557736.0000 - val_mean_squared_error: 8557738.0000 - val_mean_absolute_error: 1449.3629\n",
      "Epoch 14/20\n",
      "35996/35996 [==============================] - 0s - loss: 9164750.2963 - mean_squared_error: 9164750.9078 - mean_absolute_error: 1670.9933 - val_loss: 8884311.0000 - val_mean_squared_error: 8884312.0000 - val_mean_absolute_error: 1471.0100\n",
      "Epoch 15/20\n",
      "35996/35996 [==============================] - 0s - loss: 9781313.0469 - mean_squared_error: 9781313.4359 - mean_absolute_error: 1719.3243 - val_loss: 8786593.0000 - val_mean_squared_error: 8786593.0000 - val_mean_absolute_error: 1459.5947\n",
      "Epoch 16/20\n",
      "35996/35996 [==============================] - 0s - loss: 9540272.5291 - mean_squared_error: 9540273.0293 - mean_absolute_error: 1693.7368 - val_loss: 8867630.0000 - val_mean_squared_error: 8867631.0000 - val_mean_absolute_error: 1457.3094\n",
      "Epoch 17/20\n",
      "35996/35996 [==============================] - 0s - loss: 9687807.5904 - mean_squared_error: 9687808.3685 - mean_absolute_error: 1698.0199 - val_loss: 9286062.0000 - val_mean_squared_error: 9286063.0000 - val_mean_absolute_error: 1483.3774\n",
      "Epoch 18/20\n",
      "35996/35996 [==============================] - 0s - loss: 9903305.2359 - mean_squared_error: 9903305.7362 - mean_absolute_error: 1709.0245 - val_loss: 9086190.0000 - val_mean_squared_error: 9086191.0000 - val_mean_absolute_error: 1472.2137\n",
      "Epoch 19/20\n",
      "35996/35996 [==============================] - 0s - loss: 9717734.4552 - mean_squared_error: 9717734.3998 - mean_absolute_error: 1700.5590 - val_loss: 9038635.0000 - val_mean_squared_error: 9038636.0000 - val_mean_absolute_error: 1483.1423\n",
      "Epoch 20/20\n",
      "35996/35996 [==============================] - 0s - loss: 9776645.1702 - mean_squared_error: 9776645.7818 - mean_absolute_error: 1706.8232 - val_loss: 8662999.0000 - val_mean_squared_error: 8663000.0000 - val_mean_absolute_error: 1444.0360\n",
      "Saving training outputs\n",
      "Saving testing outputs\n",
      "Saving Histology blind test outputs\n",
      "Hist 72: Input Array Shape (7272, 50)\n",
      "Output Hist 72: Array Shape (7272, 50)\n",
      "Saving Vishabyte Predictions\n",
      "Vishabyte: Input Array Shape (544050, 50)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_l",
   "language": "python",
   "name": "deep_l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
